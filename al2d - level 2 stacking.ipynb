{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- age, memmonths, R3 (and R3.na), allgames1yr, hasemail\n",
    "\n",
    "- I found that the extra features make GAM better, but not the other features. I think because GAM can capture the shape of the distribution of the predictors better â€” the NN/RF/GLM can't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# true, then pred\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import preprocessing\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('notebook')\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sknn.mlp import Classifier, Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import amyutility as p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'amyutility' from 'amyutility.pyc'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43436, 23)\n",
      "(14479, 23)\n"
     ]
    }
   ],
   "source": [
    "print train.shape\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traink = pd.read_csv('data/fromKen/full_train_2.csv')\n",
    "testk = pd.read_csv('data/fromKen/full_test_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43436, 56)\n",
      "(14479, 55)\n"
     ]
    }
   ],
   "source": [
    "print traink.shape\n",
    "print testk.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memtype</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.00</td>\n",
       "      <td>M</td>\n",
       "      <td>reg127</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2024.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.00</td>\n",
       "      <td>M</td>\n",
       "      <td>reg142</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>258</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2753.00</td>\n",
       "      <td>2751.00</td>\n",
       "      <td>2709.00</td>\n",
       "      <td>3528.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>nan</td>\n",
       "      <td>10</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.00</td>\n",
       "      <td>M</td>\n",
       "      <td>reg104</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>28</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1668.00</td>\n",
       "      <td>2910.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>nan</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.00</td>\n",
       "      <td>M</td>\n",
       "      <td>reg112</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>14</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>741.00</td>\n",
       "      <td>1107.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>nan</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.00</td>\n",
       "      <td>F</td>\n",
       "      <td>reg106</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>131</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>359.00</td>\n",
       "      <td>325.00</td>\n",
       "      <td>531.00</td>\n",
       "      <td>654.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>nan</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age sex  region  nregions memtype  memmonths mem_mag1 mem_mag2 hasemail      r1      r2      r3  r.quick extra intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  Id\n",
       "0 29.00   M  reg127         1       N          2        Y        N        N     nan     nan 2024.00      nan     N    N     nan            0            0           0          0           0       0   1\n",
       "1 16.00   M  reg142         1       N        258        N        N        Y 2753.00 2751.00 2709.00  3528.00     N    N     nan           10          223           0         57           7       0   2\n",
       "2 22.00   M  reg104         1       N         28        N        N        Y     nan     nan 1668.00  2910.00     N    N     nan            6            6           2          1           0       0   3\n",
       "3 10.00   M  reg112         1       N         14        N        N        Y     nan     nan  741.00  1107.00     N    N     nan           13           13           0          2           1       0   4\n",
       "4 14.00   F  reg106         1       N        131        N        N        N  359.00  325.00  531.00   654.00     N    N     nan           14           57           0         16           1       0   5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'lapsed', u'age', u'sex', u'region', u'nregions', u'memtype', u'memmonths', u'mem_mag1', u'mem_mag2', u'hasemail', u'r1', u'r2', u'r3', u'r.quick', u'extra', u'intl', u'r.intl', u'allgames1yr', u'allgames5yr', u'fastevents', u'medevents', u'slowevents', u'nfloor'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Ken's Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'lapsed', u'age', u'sex', u'region', u'nregions', u'memtype', u'memmonths', u'mem_mag1', u'mem_mag2', u'hasemail', u'r1', u'r2', u'r3', u'r.quick', u'extra', u'intl', u'r.intl', u'allgames1yr', u'allgames5yr', u'fastevents', u'medevents', u'slowevents', u'nfloor', u'age.na', u'r1.na', u'r2.na', u'r3.na', u'r.quick.na', u'r.intl.na', u'mon_less30', u'mon_31', u'mon_32', u'mon_33', u'mon_34', u'mon_35', u'mon_36', u'mon_37_60', u'mon_61_84', u'mon_85_120', u'mon_121_263', u'mon_264_plus',\n",
       "       u'games_0', u'games_1_5', u'games_6_10', u'games_11_20', u'games_21_34', u'games_35_49', u'games_50_plus', u'agesq', u'agecbd', u'allgames1yrsq', u'allgames1yrcbd', u'allgames5yrsq', u'allgames5yrcbd', u'memmonthssq', u'memmonthscbd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traink.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'age', u'sex', u'region', u'nregions', u'memtype', u'memmonths', u'mem_mag1', u'mem_mag2', u'hasemail', u'r1', u'r2', u'r3', u'r.quick', u'extra', u'intl', u'r.intl', u'allgames1yr', u'allgames5yr', u'fastevents', u'medevents', u'slowevents', u'nfloor', u'age.na', u'r1.na', u'r2.na', u'r3.na', u'r.quick.na', u'r.intl.na', u'mon_less30', u'mon_31', u'mon_32', u'mon_33', u'mon_34', u'mon_35', u'mon_36', u'mon_37_60', u'mon_61_84', u'mon_85_120', u'mon_121_263', u'mon_264_plus',\n",
       "       u'games_0', u'games_1_5', u'games_6_10', u'games_11_20', u'games_21_34', u'games_35_49', u'games_50_plus', u'agesq', u'agecbd', u'allgames1yrsq', u'allgames1yrcbd', u'allgames5yrsq', u'allgames5yrcbd', u'memmonthssq', u'memmonthscbd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testk.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lapsed</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memtype</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>age.na</th>\n",
       "      <th>r1.na</th>\n",
       "      <th>r2.na</th>\n",
       "      <th>r3.na</th>\n",
       "      <th>r.quick.na</th>\n",
       "      <th>r.intl.na</th>\n",
       "      <th>mon_less30</th>\n",
       "      <th>mon_31</th>\n",
       "      <th>mon_32</th>\n",
       "      <th>mon_33</th>\n",
       "      <th>mon_34</th>\n",
       "      <th>mon_35</th>\n",
       "      <th>mon_36</th>\n",
       "      <th>mon_37_60</th>\n",
       "      <th>mon_61_84</th>\n",
       "      <th>mon_85_120</th>\n",
       "      <th>mon_121_263</th>\n",
       "      <th>mon_264_plus</th>\n",
       "      <th>games_0</th>\n",
       "      <th>games_1_5</th>\n",
       "      <th>games_6_10</th>\n",
       "      <th>games_11_20</th>\n",
       "      <th>games_21_34</th>\n",
       "      <th>games_35_49</th>\n",
       "      <th>games_50_plus</th>\n",
       "      <th>agesq</th>\n",
       "      <th>agecbd</th>\n",
       "      <th>allgames1yrsq</th>\n",
       "      <th>allgames1yrcbd</th>\n",
       "      <th>allgames5yrsq</th>\n",
       "      <th>allgames5yrcbd</th>\n",
       "      <th>memmonthssq</th>\n",
       "      <th>memmonthscbd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>11.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>1557.56</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.99</td>\n",
       "      <td>8.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>61.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>198</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2178.00</td>\n",
       "      <td>2215.00</td>\n",
       "      <td>2291.00</td>\n",
       "      <td>2932.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.25</td>\n",
       "      <td>12.38</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.59</td>\n",
       "      <td>15.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>16.00</td>\n",
       "      <td>F</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>192</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>627.00</td>\n",
       "      <td>628.00</td>\n",
       "      <td>1362.00</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.53</td>\n",
       "      <td>15.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>47.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>268</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2600.00</td>\n",
       "      <td>2601.00</td>\n",
       "      <td>2602.00</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.74</td>\n",
       "      <td>11.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.19</td>\n",
       "      <td>16.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y</td>\n",
       "      <td>11.00</td>\n",
       "      <td>F</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>464.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>958.00</td>\n",
       "      <td>1356.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.25</td>\n",
       "      <td>13.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lapsed   age sex  region  nregions memtype  memmonths mem_mag1 mem_mag2 hasemail      r1      r2      r3  r.quick extra intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  age.na  r1.na  r2.na  r3.na  r.quick.na  r.intl.na mon_less30 mon_31 mon_32 mon_33 mon_34 mon_35 mon_36 mon_37_60 mon_61_84 mon_85_120 mon_121_263 mon_264_plus games_0 games_1_5 games_6_10 games_11_20 games_21_34 games_35_49 games_50_plus  agesq  agecbd  allgames1yrsq  allgames1yrcbd  \\\n",
       "0      Y 11.00   M    0.12         1       N         19        N        N        N 1942.12 1811.61 1557.56  2007.74     N    N 3477.56            0            0           0          0           0       0       0      1      1      1           1          1       True  False  False  False  False  False  False     False     False      False       False        False    True     False      False       False       False       False         False   4.97    7.45           0.00            0.00   \n",
       "1      N 61.00   M    0.12         1       N        198        Y        N        Y 2178.00 2215.00 2291.00  2932.00     Y    N 3477.56            4           29           1          0          10       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False      True      False       False       False       False          True   8.25   12.38           3.22            4.83   \n",
       "2      Y 16.00   F    0.12         1       N        192        N        N        Y  627.00  628.00 1362.00  2007.00     N    N 3477.56           29           29           0          4           1       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False      False       False        True       False          True   5.67    8.50           6.80           10.20   \n",
       "3      Y 47.00   M    0.12         1       N        268        Y        N        Y 2600.00 2601.00 2602.00  2007.74     N    N 3477.56            0            0           0          0           0       0       0      0      0      0           1          1      False  False  False  False  False  False  False     False     False      False       False         True    True     False      False       False       False       False          True   7.74   11.61           0.00            0.00   \n",
       "4      Y 11.00   F    0.12         1       N        101        N        N        N  464.00  466.00  958.00  1356.00     N    N 3477.56           12           35           0          8           0       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False       True       False        False   False     False      False        True       False       False          True   4.97    7.45           5.13            7.69   \n",
       "\n",
       "   allgames5yrsq  allgames5yrcbd  memmonthssq  memmonthscbd  \n",
       "0           0.00            0.00         5.99          8.99  \n",
       "1           6.80           10.20        10.59         15.88  \n",
       "2           6.80           10.20        10.53         15.79  \n",
       "3           0.00            0.00        11.19         16.78  \n",
       "4           7.17           10.75         9.25         13.87  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traink.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memtype</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>age.na</th>\n",
       "      <th>r1.na</th>\n",
       "      <th>r2.na</th>\n",
       "      <th>r3.na</th>\n",
       "      <th>r.quick.na</th>\n",
       "      <th>r.intl.na</th>\n",
       "      <th>mon_less30</th>\n",
       "      <th>mon_31</th>\n",
       "      <th>mon_32</th>\n",
       "      <th>mon_33</th>\n",
       "      <th>mon_34</th>\n",
       "      <th>mon_35</th>\n",
       "      <th>mon_36</th>\n",
       "      <th>mon_37_60</th>\n",
       "      <th>mon_61_84</th>\n",
       "      <th>mon_85_120</th>\n",
       "      <th>mon_121_263</th>\n",
       "      <th>mon_264_plus</th>\n",
       "      <th>games_0</th>\n",
       "      <th>games_1_5</th>\n",
       "      <th>games_6_10</th>\n",
       "      <th>games_11_20</th>\n",
       "      <th>games_21_34</th>\n",
       "      <th>games_35_49</th>\n",
       "      <th>games_50_plus</th>\n",
       "      <th>agesq</th>\n",
       "      <th>agecbd</th>\n",
       "      <th>allgames1yrsq</th>\n",
       "      <th>allgames1yrcbd</th>\n",
       "      <th>allgames5yrsq</th>\n",
       "      <th>allgames5yrcbd</th>\n",
       "      <th>memmonthssq</th>\n",
       "      <th>memmonthscbd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>2024.00</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>258</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2753.00</td>\n",
       "      <td>2751.00</td>\n",
       "      <td>2709.00</td>\n",
       "      <td>3528.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>10</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.50</td>\n",
       "      <td>4.80</td>\n",
       "      <td>7.19</td>\n",
       "      <td>10.82</td>\n",
       "      <td>16.23</td>\n",
       "      <td>11.11</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>28</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>1668.00</td>\n",
       "      <td>2910.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.27</td>\n",
       "      <td>9.41</td>\n",
       "      <td>3.89</td>\n",
       "      <td>5.84</td>\n",
       "      <td>3.89</td>\n",
       "      <td>5.84</td>\n",
       "      <td>6.73</td>\n",
       "      <td>10.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>14</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>741.00</td>\n",
       "      <td>1107.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.80</td>\n",
       "      <td>7.19</td>\n",
       "      <td>5.28</td>\n",
       "      <td>7.92</td>\n",
       "      <td>5.28</td>\n",
       "      <td>7.92</td>\n",
       "      <td>5.42</td>\n",
       "      <td>8.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.00</td>\n",
       "      <td>F</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>131</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>359.00</td>\n",
       "      <td>325.00</td>\n",
       "      <td>531.00</td>\n",
       "      <td>654.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.42</td>\n",
       "      <td>8.12</td>\n",
       "      <td>5.42</td>\n",
       "      <td>8.12</td>\n",
       "      <td>8.12</td>\n",
       "      <td>12.18</td>\n",
       "      <td>9.77</td>\n",
       "      <td>14.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age sex  region  nregions memtype  memmonths mem_mag1 mem_mag2 hasemail      r1      r2      r3  r.quick extra intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  age.na  r1.na  r2.na  r3.na  r.quick.na  r.intl.na mon_less30 mon_31 mon_32 mon_33 mon_34 mon_35 mon_36 mon_37_60 mon_61_84 mon_85_120 mon_121_263 mon_264_plus games_0 games_1_5 games_6_10 games_11_20 games_21_34 games_35_49 games_50_plus  agesq  agecbd  allgames1yrsq  allgames1yrcbd  allgames5yrsq  \\\n",
       "0 29.00   M    0.11         1       N          2        Y        N        N 1942.12 1811.61 2024.00  2007.74     N    N 3477.56            0            0           0          0           0       0       0      1      1      0           1          1       True  False  False  False  False  False  False     False     False      False       False        False    True     False      False       False       False       False         False   6.80   10.20           0.00            0.00           0.00   \n",
       "1 16.00   M    0.02         1       N        258        N        N        Y 2753.00 2751.00 2709.00  3528.00     N    N 3477.56           10          223           0         57           7       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False       True       False       False       False          True   5.67    8.50           4.80            7.19          10.82   \n",
       "2 22.00   M    0.00         1       N         28        N        N        Y 1942.12 1811.61 1668.00  2910.00     N    N 3477.56            6            6           2          1           0       0       0      1      1      0           0          1       True  False  False  False  False  False  False     False     False      False       False        False   False     False       True       False       False       False         False   6.27    9.41           3.89            5.84           3.89   \n",
       "3 10.00   M    0.12         1       N         14        N        N        Y 1942.12 1811.61  741.00  1107.00     N    N 3477.56           13           13           0          2           1       0       0      1      1      0           0          1       True  False  False  False  False  False  False     False     False      False       False        False   False     False      False        True       False       False         False   4.80    7.19           5.28            7.92           5.28   \n",
       "4 14.00   F    0.04         1       N        131        N        N        N  359.00  325.00  531.00   654.00     N    N 3477.56           14           57           0         16           1       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False      False        True       False       False          True   5.42    8.12           5.42            8.12           8.12   \n",
       "\n",
       "   allgames5yrcbd  memmonthssq  memmonthscbd  \n",
       "0            0.00         2.20          3.30  \n",
       "1           16.23        11.11         16.67  \n",
       "2            5.84         6.73         10.10  \n",
       "3            7.92         5.42          8.12  \n",
       "4           12.18         9.77         14.65  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traink_y = traink[['lapsed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lapsed\n",
       "0      Y\n",
       "1      N\n",
       "2      Y\n",
       "3      Y\n",
       "4      Y"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traink_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traink_x = traink.drop('lapsed', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43436, 55)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traink_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memtype</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>age.na</th>\n",
       "      <th>r1.na</th>\n",
       "      <th>r2.na</th>\n",
       "      <th>r3.na</th>\n",
       "      <th>r.quick.na</th>\n",
       "      <th>r.intl.na</th>\n",
       "      <th>mon_less30</th>\n",
       "      <th>mon_31</th>\n",
       "      <th>mon_32</th>\n",
       "      <th>mon_33</th>\n",
       "      <th>mon_34</th>\n",
       "      <th>mon_35</th>\n",
       "      <th>mon_36</th>\n",
       "      <th>mon_37_60</th>\n",
       "      <th>mon_61_84</th>\n",
       "      <th>mon_85_120</th>\n",
       "      <th>mon_121_263</th>\n",
       "      <th>mon_264_plus</th>\n",
       "      <th>games_0</th>\n",
       "      <th>games_1_5</th>\n",
       "      <th>games_6_10</th>\n",
       "      <th>games_11_20</th>\n",
       "      <th>games_21_34</th>\n",
       "      <th>games_35_49</th>\n",
       "      <th>games_50_plus</th>\n",
       "      <th>agesq</th>\n",
       "      <th>agecbd</th>\n",
       "      <th>allgames1yrsq</th>\n",
       "      <th>allgames1yrcbd</th>\n",
       "      <th>allgames5yrsq</th>\n",
       "      <th>allgames5yrcbd</th>\n",
       "      <th>memmonthssq</th>\n",
       "      <th>memmonthscbd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>1557.56</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.99</td>\n",
       "      <td>8.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>198</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2178.00</td>\n",
       "      <td>2215.00</td>\n",
       "      <td>2291.00</td>\n",
       "      <td>2932.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.25</td>\n",
       "      <td>12.38</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.59</td>\n",
       "      <td>15.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.00</td>\n",
       "      <td>F</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>192</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>627.00</td>\n",
       "      <td>628.00</td>\n",
       "      <td>1362.00</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.53</td>\n",
       "      <td>15.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>268</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2600.00</td>\n",
       "      <td>2601.00</td>\n",
       "      <td>2602.00</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.74</td>\n",
       "      <td>11.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.19</td>\n",
       "      <td>16.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.00</td>\n",
       "      <td>F</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>464.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>958.00</td>\n",
       "      <td>1356.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.25</td>\n",
       "      <td>13.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age sex  region  nregions memtype  memmonths mem_mag1 mem_mag2 hasemail      r1      r2      r3  r.quick extra intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  age.na  r1.na  r2.na  r3.na  r.quick.na  r.intl.na mon_less30 mon_31 mon_32 mon_33 mon_34 mon_35 mon_36 mon_37_60 mon_61_84 mon_85_120 mon_121_263 mon_264_plus games_0 games_1_5 games_6_10 games_11_20 games_21_34 games_35_49 games_50_plus  agesq  agecbd  allgames1yrsq  allgames1yrcbd  allgames5yrsq  \\\n",
       "0 11.00   M    0.12         1       N         19        N        N        N 1942.12 1811.61 1557.56  2007.74     N    N 3477.56            0            0           0          0           0       0       0      1      1      1           1          1       True  False  False  False  False  False  False     False     False      False       False        False    True     False      False       False       False       False         False   4.97    7.45           0.00            0.00           0.00   \n",
       "1 61.00   M    0.12         1       N        198        Y        N        Y 2178.00 2215.00 2291.00  2932.00     Y    N 3477.56            4           29           1          0          10       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False      True      False       False       False       False          True   8.25   12.38           3.22            4.83           6.80   \n",
       "2 16.00   F    0.12         1       N        192        N        N        Y  627.00  628.00 1362.00  2007.00     N    N 3477.56           29           29           0          4           1       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False      False       False        True       False          True   5.67    8.50           6.80           10.20           6.80   \n",
       "3 47.00   M    0.12         1       N        268        Y        N        Y 2600.00 2601.00 2602.00  2007.74     N    N 3477.56            0            0           0          0           0       0       0      0      0      0           1          1      False  False  False  False  False  False  False     False     False      False       False         True    True     False      False       False       False       False          True   7.74   11.61           0.00            0.00           0.00   \n",
       "4 11.00   F    0.12         1       N        101        N        N        N  464.00  466.00  958.00  1356.00     N    N 3477.56           12           35           0          8           0       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False       True       False        False   False     False      False        True       False       False          True   4.97    7.45           5.13            7.69           7.17   \n",
       "\n",
       "   allgames5yrcbd  memmonthssq  memmonthscbd  \n",
       "0            0.00         5.99          8.99  \n",
       "1           10.20        10.59         15.88  \n",
       "2           10.20        10.53         15.79  \n",
       "3            0.00        11.19         16.78  \n",
       "4           10.75         9.25         13.87  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traink_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = (traink_y.lapsed.values=='Y')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key train_y\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     2,     3, ..., 14477, 14478, 14479])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key test_ids: for writing to predictions\n",
    "test_ids = test.Id.values\n",
    "test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# key df_all: combine test and train into df_all, test_idx \n",
    "test_idx = traink_x.shape[0]\n",
    "df_all = pd.concat((traink_x, testk), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57915, 55)\n",
      "43436\n"
     ]
    }
   ],
   "source": [
    "print df_all.shape\n",
    "print test_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key: \n",
    "- df_all\n",
    "- test_idx\n",
    "- train_y\n",
    "- test_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Types and Convert\n",
    "\n",
    "- need to convert sex, memtype, mem_mag1, mem_mag2, hasemail, extra, intl\n",
    "- Can leave bools alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CONVERT = ['sex', 'memtype', 'mem_mag1', 'mem_mag2', 'hasemail', 'extra', 'intl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sex\n",
    "\n",
    "- males 0\n",
    "- females 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAFeCAYAAACvnuTEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKABAcf4PyfuyvtiPZrgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d31db50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mostly male (males 0, females 1)\n",
    "gender = df_all.groupby('sex').size().sort_values(ascending = True)/df_all.shape[0]*100\n",
    "gender.plot(kind='barh', title = 'Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memtype</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>age.na</th>\n",
       "      <th>r1.na</th>\n",
       "      <th>r2.na</th>\n",
       "      <th>r3.na</th>\n",
       "      <th>r.quick.na</th>\n",
       "      <th>r.intl.na</th>\n",
       "      <th>mon_less30</th>\n",
       "      <th>mon_31</th>\n",
       "      <th>mon_32</th>\n",
       "      <th>mon_33</th>\n",
       "      <th>mon_34</th>\n",
       "      <th>mon_35</th>\n",
       "      <th>mon_36</th>\n",
       "      <th>mon_37_60</th>\n",
       "      <th>mon_61_84</th>\n",
       "      <th>mon_85_120</th>\n",
       "      <th>mon_121_263</th>\n",
       "      <th>mon_264_plus</th>\n",
       "      <th>games_0</th>\n",
       "      <th>games_1_5</th>\n",
       "      <th>games_6_10</th>\n",
       "      <th>games_11_20</th>\n",
       "      <th>games_21_34</th>\n",
       "      <th>games_35_49</th>\n",
       "      <th>games_50_plus</th>\n",
       "      <th>agesq</th>\n",
       "      <th>agecbd</th>\n",
       "      <th>allgames1yrsq</th>\n",
       "      <th>allgames1yrcbd</th>\n",
       "      <th>allgames5yrsq</th>\n",
       "      <th>allgames5yrcbd</th>\n",
       "      <th>memmonthssq</th>\n",
       "      <th>memmonthscbd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>1557.56</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.99</td>\n",
       "      <td>8.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>198</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2178.00</td>\n",
       "      <td>2215.00</td>\n",
       "      <td>2291.00</td>\n",
       "      <td>2932.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.25</td>\n",
       "      <td>12.38</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.59</td>\n",
       "      <td>15.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.00</td>\n",
       "      <td>F</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>192</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>627.00</td>\n",
       "      <td>628.00</td>\n",
       "      <td>1362.00</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.53</td>\n",
       "      <td>15.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>268</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2600.00</td>\n",
       "      <td>2601.00</td>\n",
       "      <td>2602.00</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.74</td>\n",
       "      <td>11.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.19</td>\n",
       "      <td>16.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.00</td>\n",
       "      <td>F</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>464.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>958.00</td>\n",
       "      <td>1356.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.25</td>\n",
       "      <td>13.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age sex  region  nregions memtype  memmonths mem_mag1 mem_mag2 hasemail      r1      r2      r3  r.quick extra intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  age.na  r1.na  r2.na  r3.na  r.quick.na  r.intl.na mon_less30 mon_31 mon_32 mon_33 mon_34 mon_35 mon_36 mon_37_60 mon_61_84 mon_85_120 mon_121_263 mon_264_plus games_0 games_1_5 games_6_10 games_11_20 games_21_34 games_35_49 games_50_plus  agesq  agecbd  allgames1yrsq  allgames1yrcbd  allgames5yrsq  \\\n",
       "0 11.00   M    0.12         1       N         19        N        N        N 1942.12 1811.61 1557.56  2007.74     N    N 3477.56            0            0           0          0           0       0       0      1      1      1           1          1       True  False  False  False  False  False  False     False     False      False       False        False    True     False      False       False       False       False         False   4.97    7.45           0.00            0.00           0.00   \n",
       "1 61.00   M    0.12         1       N        198        Y        N        Y 2178.00 2215.00 2291.00  2932.00     Y    N 3477.56            4           29           1          0          10       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False      True      False       False       False       False          True   8.25   12.38           3.22            4.83           6.80   \n",
       "2 16.00   F    0.12         1       N        192        N        N        Y  627.00  628.00 1362.00  2007.00     N    N 3477.56           29           29           0          4           1       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False      False       False        True       False          True   5.67    8.50           6.80           10.20           6.80   \n",
       "3 47.00   M    0.12         1       N        268        Y        N        Y 2600.00 2601.00 2602.00  2007.74     N    N 3477.56            0            0           0          0           0       0       0      0      0      0           1          1      False  False  False  False  False  False  False     False     False      False       False         True    True     False      False       False       False       False          True   7.74   11.61           0.00            0.00           0.00   \n",
       "4 11.00   F    0.12         1       N        101        N        N        N  464.00  466.00  958.00  1356.00     N    N 3477.56           12           35           0          8           0       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False       True       False        False   False     False      False        True       False       False          True   4.97    7.45           5.13            7.69           7.17   \n",
       "\n",
       "   allgames5yrcbd  memmonthssq  memmonthscbd  \n",
       "0            0.00         5.99          8.99  \n",
       "1           10.20        10.59         15.88  \n",
       "2           10.20        10.53         15.79  \n",
       "3            0.00        11.19         16.78  \n",
       "4           10.75         9.25         13.87  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               float64\n",
       "sex                object\n",
       "region            float64\n",
       "nregions            int64\n",
       "memtype            object\n",
       "memmonths           int64\n",
       "mem_mag1           object\n",
       "mem_mag2           object\n",
       "hasemail           object\n",
       "r1                float64\n",
       "r2                float64\n",
       "r3                float64\n",
       "r.quick           float64\n",
       "extra              object\n",
       "intl               object\n",
       "r.intl            float64\n",
       "allgames1yr         int64\n",
       "allgames5yr         int64\n",
       "fastevents          int64\n",
       "medevents           int64\n",
       "slowevents          int64\n",
       "nfloor              int64\n",
       "age.na              int64\n",
       "r1.na               int64\n",
       "r2.na               int64\n",
       "r3.na               int64\n",
       "r.quick.na          int64\n",
       "r.intl.na           int64\n",
       "mon_less30           bool\n",
       "mon_31               bool\n",
       "mon_32               bool\n",
       "mon_33               bool\n",
       "mon_34               bool\n",
       "mon_35               bool\n",
       "mon_36               bool\n",
       "mon_37_60            bool\n",
       "mon_61_84            bool\n",
       "mon_85_120           bool\n",
       "mon_121_263          bool\n",
       "mon_264_plus         bool\n",
       "games_0              bool\n",
       "games_1_5            bool\n",
       "games_6_10           bool\n",
       "games_11_20          bool\n",
       "games_21_34          bool\n",
       "games_35_49          bool\n",
       "games_50_plus        bool\n",
       "agesq             float64\n",
       "agecbd            float64\n",
       "allgames1yrsq     float64\n",
       "allgames1yrcbd    float64\n",
       "allgames5yrsq     float64\n",
       "allgames5yrcbd    float64\n",
       "memmonthssq       float64\n",
       "memmonthscbd      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 M\n",
       "1                 M\n",
       "2                 F\n",
       "3                 M\n",
       "4                 F\n",
       "5                 F\n",
       "6                 M\n",
       "7                 M\n",
       "8                 M\n",
       "9                 M\n",
       "10                M\n",
       "11                M\n",
       "12                M\n",
       "13                M\n",
       "14                M\n",
       "15                F\n",
       "16                M\n",
       "17                M\n",
       "18                F\n",
       "19                M\n",
       "20                M\n",
       "21                F\n",
       "22                M\n",
       "23                M\n",
       "24                M\n",
       "25                M\n",
       "26                M\n",
       "27                M\n",
       "28                F\n",
       "29                M\n",
       "30                M\n",
       "31                M\n",
       "32                M\n",
       "33                F\n",
       "34                M\n",
       "35                M\n",
       "36                M\n",
       "37                M\n",
       "38                M\n",
       "39                F\n",
       "40                M\n",
       "41                M\n",
       "42                M\n",
       "43                F\n",
       "44                M\n",
       "45                M\n",
       "46                M\n",
       "47                M\n",
       "48                M\n",
       "49                M\n",
       "50                M\n",
       "51                M\n",
       "52                F\n",
       "53                M\n",
       "54                M\n",
       "55                F\n",
       "56                M\n",
       "57                M\n",
       "58                M\n",
       "59                M\n",
       "60                M\n",
       "61       Z_dummy_NA\n",
       "62                M\n",
       "63                M\n",
       "64                M\n",
       "65                M\n",
       "66                M\n",
       "67                M\n",
       "68                M\n",
       "69                M\n",
       "70                M\n",
       "71                M\n",
       "72                M\n",
       "73                M\n",
       "74                M\n",
       "75                M\n",
       "76                M\n",
       "77                M\n",
       "78                M\n",
       "79                M\n",
       "80       Z_dummy_NA\n",
       "81                M\n",
       "82                F\n",
       "83                M\n",
       "84                M\n",
       "85       Z_dummy_NA\n",
       "86                F\n",
       "87                M\n",
       "88                M\n",
       "89                M\n",
       "90                M\n",
       "91                M\n",
       "92                M\n",
       "93                M\n",
       "94                M\n",
       "95                M\n",
       "96                M\n",
       "97                M\n",
       "98                M\n",
       "99                M\n",
       "            ...    \n",
       "14379             M\n",
       "14380             M\n",
       "14381             M\n",
       "14382             M\n",
       "14383             M\n",
       "14384             F\n",
       "14385             M\n",
       "14386             M\n",
       "14387             M\n",
       "14388             M\n",
       "14389             M\n",
       "14390             M\n",
       "14391             M\n",
       "14392             M\n",
       "14393             M\n",
       "14394             M\n",
       "14395             M\n",
       "14396             M\n",
       "14397             M\n",
       "14398             M\n",
       "14399             M\n",
       "14400             M\n",
       "14401             M\n",
       "14402             M\n",
       "14403             M\n",
       "14404             M\n",
       "14405             M\n",
       "14406             F\n",
       "14407             M\n",
       "14408             M\n",
       "14409             F\n",
       "14410             M\n",
       "14411             M\n",
       "14412             M\n",
       "14413             M\n",
       "14414             M\n",
       "14415             M\n",
       "14416             M\n",
       "14417             M\n",
       "14418             M\n",
       "14419             M\n",
       "14420             M\n",
       "14421             F\n",
       "14422             M\n",
       "14423             M\n",
       "14424    Z_dummy_NA\n",
       "14425             M\n",
       "14426             F\n",
       "14427             M\n",
       "14428             M\n",
       "14429             M\n",
       "14430             M\n",
       "14431             F\n",
       "14432             M\n",
       "14433             M\n",
       "14434             M\n",
       "14435             M\n",
       "14436             M\n",
       "14437             M\n",
       "14438             M\n",
       "14439    Z_dummy_NA\n",
       "14440             M\n",
       "14441             M\n",
       "14442             M\n",
       "14443             M\n",
       "14444             M\n",
       "14445             M\n",
       "14446             M\n",
       "14447             M\n",
       "14448             M\n",
       "14449             F\n",
       "14450             M\n",
       "14451             M\n",
       "14452             M\n",
       "14453             M\n",
       "14454             M\n",
       "14455             M\n",
       "14456             M\n",
       "14457             F\n",
       "14458             M\n",
       "14459             M\n",
       "14460             M\n",
       "14461             M\n",
       "14462             M\n",
       "14463             M\n",
       "14464             M\n",
       "14465             M\n",
       "14466             F\n",
       "14467             M\n",
       "14468             M\n",
       "14469             F\n",
       "14470             M\n",
       "14471             M\n",
       "14472             M\n",
       "14473             F\n",
       "14474    Z_dummy_NA\n",
       "14475             F\n",
       "14476             M\n",
       "14477             M\n",
       "14478             M\n",
       "Name: sex, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.sex = (df_all.sex.values=='F')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memtype</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>age.na</th>\n",
       "      <th>r1.na</th>\n",
       "      <th>r2.na</th>\n",
       "      <th>r3.na</th>\n",
       "      <th>r.quick.na</th>\n",
       "      <th>r.intl.na</th>\n",
       "      <th>mon_less30</th>\n",
       "      <th>mon_31</th>\n",
       "      <th>mon_32</th>\n",
       "      <th>mon_33</th>\n",
       "      <th>mon_34</th>\n",
       "      <th>mon_35</th>\n",
       "      <th>mon_36</th>\n",
       "      <th>mon_37_60</th>\n",
       "      <th>mon_61_84</th>\n",
       "      <th>mon_85_120</th>\n",
       "      <th>mon_121_263</th>\n",
       "      <th>mon_264_plus</th>\n",
       "      <th>games_0</th>\n",
       "      <th>games_1_5</th>\n",
       "      <th>games_6_10</th>\n",
       "      <th>games_11_20</th>\n",
       "      <th>games_21_34</th>\n",
       "      <th>games_35_49</th>\n",
       "      <th>games_50_plus</th>\n",
       "      <th>agesq</th>\n",
       "      <th>agecbd</th>\n",
       "      <th>allgames1yrsq</th>\n",
       "      <th>allgames1yrcbd</th>\n",
       "      <th>allgames5yrsq</th>\n",
       "      <th>allgames5yrcbd</th>\n",
       "      <th>memmonthssq</th>\n",
       "      <th>memmonthscbd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>1557.56</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.99</td>\n",
       "      <td>8.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>198</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2178.00</td>\n",
       "      <td>2215.00</td>\n",
       "      <td>2291.00</td>\n",
       "      <td>2932.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.25</td>\n",
       "      <td>12.38</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.59</td>\n",
       "      <td>15.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>192</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>627.00</td>\n",
       "      <td>628.00</td>\n",
       "      <td>1362.00</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.53</td>\n",
       "      <td>15.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>268</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2600.00</td>\n",
       "      <td>2601.00</td>\n",
       "      <td>2602.00</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.74</td>\n",
       "      <td>11.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.19</td>\n",
       "      <td>16.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>464.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>958.00</td>\n",
       "      <td>1356.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.25</td>\n",
       "      <td>13.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  region  nregions memtype  memmonths mem_mag1 mem_mag2 hasemail      r1      r2      r3  r.quick extra intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  age.na  r1.na  r2.na  r3.na  r.quick.na  r.intl.na mon_less30 mon_31 mon_32 mon_33 mon_34 mon_35 mon_36 mon_37_60 mon_61_84 mon_85_120 mon_121_263 mon_264_plus games_0 games_1_5 games_6_10 games_11_20 games_21_34 games_35_49 games_50_plus  agesq  agecbd  allgames1yrsq  allgames1yrcbd  \\\n",
       "0 11.00    0    0.12         1       N         19        N        N        N 1942.12 1811.61 1557.56  2007.74     N    N 3477.56            0            0           0          0           0       0       0      1      1      1           1          1       True  False  False  False  False  False  False     False     False      False       False        False    True     False      False       False       False       False         False   4.97    7.45           0.00            0.00   \n",
       "1 61.00    0    0.12         1       N        198        Y        N        Y 2178.00 2215.00 2291.00  2932.00     Y    N 3477.56            4           29           1          0          10       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False      True      False       False       False       False          True   8.25   12.38           3.22            4.83   \n",
       "2 16.00    1    0.12         1       N        192        N        N        Y  627.00  628.00 1362.00  2007.00     N    N 3477.56           29           29           0          4           1       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False      False       False        True       False          True   5.67    8.50           6.80           10.20   \n",
       "3 47.00    0    0.12         1       N        268        Y        N        Y 2600.00 2601.00 2602.00  2007.74     N    N 3477.56            0            0           0          0           0       0       0      0      0      0           1          1      False  False  False  False  False  False  False     False     False      False       False         True    True     False      False       False       False       False          True   7.74   11.61           0.00            0.00   \n",
       "4 11.00    1    0.12         1       N        101        N        N        N  464.00  466.00  958.00  1356.00     N    N 3477.56           12           35           0          8           0       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False       True       False        False   False     False      False        True       False       False          True   4.97    7.45           5.13            7.69   \n",
       "\n",
       "   allgames5yrsq  allgames5yrcbd  memmonthssq  memmonthscbd  \n",
       "0           0.00            0.00         5.99          8.99  \n",
       "1           6.80           10.20        10.59         15.88  \n",
       "2           6.80           10.20        10.53         15.79  \n",
       "3           0.00            0.00        11.19         16.78  \n",
       "4           7.17           10.75         9.25         13.87  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### memtype\n",
    "- make Normal the reference category\n",
    "- memtypeA=1 for affiliate\n",
    "- memtypeF=1 for family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFeCAYAAACsH5cdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d7faa50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# membership types A, F, N \n",
    "memtype = df_all.groupby('memtype').size().sort_values(ascending = True)/df_all.shape[0]*100\n",
    "memtype.plot(kind='barh', title = 'Memtype')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['memtypeA'] = (df_all.memtype=='A')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['memtypeF'] = (df_all.memtype=='F')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all = df_all.drop('memtype', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mem_mag1 & mem_mag2 & hasemail\n",
    "\n",
    "- only yes or no... convert yes to 1, no to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFeCAYAAACsH5cdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAGAM8QYAwBjiDQCAMcQbAABj/g8VjRY/U6OGdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d7e5650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "memmag1 = df_all.groupby('mem_mag1').size().sort_values(ascending = True)/df_all.shape[0]*100\n",
    "memmag1.plot(kind='barh', title = 'mem_mag1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFeCAYAAAB+T51FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d7c5b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "memmag2 = df_all.groupby('mem_mag2').size().sort_values(ascending = True)/df_all.shape[0]*100\n",
    "memmag2.plot(kind='barh', title = 'mem_mag2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFeCAYAAACsH5cdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcQbAABjiDcAAMYQbwAAjCHeAAAY828pa7jssE1jJgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e46d4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hasemail = df_all.groupby('hasemail').size().sort_values(ascending = True)/df_all.shape[0]*100\n",
    "hasemail.plot(kind='barh', title = 'hasemail')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.mem_mag1 = (df_all.mem_mag1.values=='Y')*1\n",
    "df_all.mem_mag2 = (df_all.mem_mag2.values=='Y')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.hasemail = (df_all.hasemail.values=='Y')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>age.na</th>\n",
       "      <th>r1.na</th>\n",
       "      <th>r2.na</th>\n",
       "      <th>r3.na</th>\n",
       "      <th>r.quick.na</th>\n",
       "      <th>r.intl.na</th>\n",
       "      <th>mon_less30</th>\n",
       "      <th>mon_31</th>\n",
       "      <th>mon_32</th>\n",
       "      <th>mon_33</th>\n",
       "      <th>mon_34</th>\n",
       "      <th>mon_35</th>\n",
       "      <th>mon_36</th>\n",
       "      <th>mon_37_60</th>\n",
       "      <th>mon_61_84</th>\n",
       "      <th>mon_85_120</th>\n",
       "      <th>mon_121_263</th>\n",
       "      <th>mon_264_plus</th>\n",
       "      <th>games_0</th>\n",
       "      <th>games_1_5</th>\n",
       "      <th>games_6_10</th>\n",
       "      <th>games_11_20</th>\n",
       "      <th>games_21_34</th>\n",
       "      <th>games_35_49</th>\n",
       "      <th>games_50_plus</th>\n",
       "      <th>agesq</th>\n",
       "      <th>agecbd</th>\n",
       "      <th>allgames1yrsq</th>\n",
       "      <th>allgames1yrcbd</th>\n",
       "      <th>allgames5yrsq</th>\n",
       "      <th>allgames5yrcbd</th>\n",
       "      <th>memmonthssq</th>\n",
       "      <th>memmonthscbd</th>\n",
       "      <th>memtypeA</th>\n",
       "      <th>memtypeF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>1557.56</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.99</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2178.00</td>\n",
       "      <td>2215.00</td>\n",
       "      <td>2291.00</td>\n",
       "      <td>2932.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.25</td>\n",
       "      <td>12.38</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.59</td>\n",
       "      <td>15.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>627.00</td>\n",
       "      <td>628.00</td>\n",
       "      <td>1362.00</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.53</td>\n",
       "      <td>15.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2600.00</td>\n",
       "      <td>2601.00</td>\n",
       "      <td>2602.00</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.74</td>\n",
       "      <td>11.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.19</td>\n",
       "      <td>16.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>464.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>958.00</td>\n",
       "      <td>1356.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.25</td>\n",
       "      <td>13.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  region  nregions  memmonths  mem_mag1  mem_mag2  hasemail      r1      r2      r3  r.quick extra intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  age.na  r1.na  r2.na  r3.na  r.quick.na  r.intl.na mon_less30 mon_31 mon_32 mon_33 mon_34 mon_35 mon_36 mon_37_60 mon_61_84 mon_85_120 mon_121_263 mon_264_plus games_0 games_1_5 games_6_10 games_11_20 games_21_34 games_35_49 games_50_plus  agesq  agecbd  allgames1yrsq  allgames1yrcbd  allgames5yrsq  \\\n",
       "0 11.00    0    0.12         1         19         0         0         0 1942.12 1811.61 1557.56  2007.74     N    N 3477.56            0            0           0          0           0       0       0      1      1      1           1          1       True  False  False  False  False  False  False     False     False      False       False        False    True     False      False       False       False       False         False   4.97    7.45           0.00            0.00           0.00   \n",
       "1 61.00    0    0.12         1        198         1         0         1 2178.00 2215.00 2291.00  2932.00     Y    N 3477.56            4           29           1          0          10       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False      True      False       False       False       False          True   8.25   12.38           3.22            4.83           6.80   \n",
       "2 16.00    1    0.12         1        192         0         0         1  627.00  628.00 1362.00  2007.00     N    N 3477.56           29           29           0          4           1       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False      False       False        True       False          True   5.67    8.50           6.80           10.20           6.80   \n",
       "3 47.00    0    0.12         1        268         1         0         1 2600.00 2601.00 2602.00  2007.74     N    N 3477.56            0            0           0          0           0       0       0      0      0      0           1          1      False  False  False  False  False  False  False     False     False      False       False         True    True     False      False       False       False       False          True   7.74   11.61           0.00            0.00           0.00   \n",
       "4 11.00    1    0.12         1        101         0         0         0  464.00  466.00  958.00  1356.00     N    N 3477.56           12           35           0          8           0       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False       True       False        False   False     False      False        True       False       False          True   4.97    7.45           5.13            7.69           7.17   \n",
       "\n",
       "   allgames5yrcbd  memmonthssq  memmonthscbd  memtypeA  memtypeF  \n",
       "0            0.00         5.99          8.99         0         0  \n",
       "1           10.20        10.59         15.88         0         0  \n",
       "2           10.20        10.53         15.79         0         0  \n",
       "3            0.00        11.19         16.78         0         0  \n",
       "4           10.75         9.25         13.87         0         0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extra, intl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFeCAYAAAB+T51FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d4f9210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extra = df_all.groupby('extra').size().sort_values(ascending = True)/df_all.shape[0]*100\n",
    "extra.plot(kind='barh', title = 'extra')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFeCAYAAACsH5cdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3gBQjHgDQDHiDQDFiDcAFPM/+ic1i4HfanwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110a62090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "intl = df_all.groupby('intl').size().sort_values(ascending = True)/df_all.shape[0]*100\n",
    "intl.plot(kind='barh', title = 'intl')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.extra = (df_all.extra.values=='Y')*1\n",
    "df_all.intl = (df_all.intl.values=='Y')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>age.na</th>\n",
       "      <th>r1.na</th>\n",
       "      <th>r2.na</th>\n",
       "      <th>r3.na</th>\n",
       "      <th>r.quick.na</th>\n",
       "      <th>r.intl.na</th>\n",
       "      <th>mon_less30</th>\n",
       "      <th>mon_31</th>\n",
       "      <th>mon_32</th>\n",
       "      <th>mon_33</th>\n",
       "      <th>mon_34</th>\n",
       "      <th>mon_35</th>\n",
       "      <th>mon_36</th>\n",
       "      <th>mon_37_60</th>\n",
       "      <th>mon_61_84</th>\n",
       "      <th>mon_85_120</th>\n",
       "      <th>mon_121_263</th>\n",
       "      <th>mon_264_plus</th>\n",
       "      <th>games_0</th>\n",
       "      <th>games_1_5</th>\n",
       "      <th>games_6_10</th>\n",
       "      <th>games_11_20</th>\n",
       "      <th>games_21_34</th>\n",
       "      <th>games_35_49</th>\n",
       "      <th>games_50_plus</th>\n",
       "      <th>agesq</th>\n",
       "      <th>agecbd</th>\n",
       "      <th>allgames1yrsq</th>\n",
       "      <th>allgames1yrcbd</th>\n",
       "      <th>allgames5yrsq</th>\n",
       "      <th>allgames5yrcbd</th>\n",
       "      <th>memmonthssq</th>\n",
       "      <th>memmonthscbd</th>\n",
       "      <th>memtypeA</th>\n",
       "      <th>memtypeF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>1557.56</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.99</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2178.00</td>\n",
       "      <td>2215.00</td>\n",
       "      <td>2291.00</td>\n",
       "      <td>2932.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.25</td>\n",
       "      <td>12.38</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.59</td>\n",
       "      <td>15.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>627.00</td>\n",
       "      <td>628.00</td>\n",
       "      <td>1362.00</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.53</td>\n",
       "      <td>15.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2600.00</td>\n",
       "      <td>2601.00</td>\n",
       "      <td>2602.00</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.74</td>\n",
       "      <td>11.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.19</td>\n",
       "      <td>16.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>464.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>958.00</td>\n",
       "      <td>1356.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.25</td>\n",
       "      <td>13.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  region  nregions  memmonths  mem_mag1  mem_mag2  hasemail      r1      r2      r3  r.quick  extra  intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  age.na  r1.na  r2.na  r3.na  r.quick.na  r.intl.na mon_less30 mon_31 mon_32 mon_33 mon_34 mon_35 mon_36 mon_37_60 mon_61_84 mon_85_120 mon_121_263 mon_264_plus games_0 games_1_5 games_6_10 games_11_20 games_21_34 games_35_49 games_50_plus  agesq  agecbd  allgames1yrsq  allgames1yrcbd  allgames5yrsq  \\\n",
       "0 11.00    0    0.12         1         19         0         0         0 1942.12 1811.61 1557.56  2007.74      0     0 3477.56            0            0           0          0           0       0       0      1      1      1           1          1       True  False  False  False  False  False  False     False     False      False       False        False    True     False      False       False       False       False         False   4.97    7.45           0.00            0.00           0.00   \n",
       "1 61.00    0    0.12         1        198         1         0         1 2178.00 2215.00 2291.00  2932.00      1     0 3477.56            4           29           1          0          10       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False      True      False       False       False       False          True   8.25   12.38           3.22            4.83           6.80   \n",
       "2 16.00    1    0.12         1        192         0         0         1  627.00  628.00 1362.00  2007.00      0     0 3477.56           29           29           0          4           1       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False      False       False        True       False          True   5.67    8.50           6.80           10.20           6.80   \n",
       "3 47.00    0    0.12         1        268         1         0         1 2600.00 2601.00 2602.00  2007.74      0     0 3477.56            0            0           0          0           0       0       0      0      0      0           1          1      False  False  False  False  False  False  False     False     False      False       False         True    True     False      False       False       False       False          True   7.74   11.61           0.00            0.00           0.00   \n",
       "4 11.00    1    0.12         1        101         0         0         0  464.00  466.00  958.00  1356.00      0     0 3477.56           12           35           0          8           0       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False       True       False        False   False     False      False        True       False       False          True   4.97    7.45           5.13            7.69           7.17   \n",
       "\n",
       "   allgames5yrcbd  memmonthssq  memmonthscbd  memtypeA  memtypeF  \n",
       "0            0.00         5.99          8.99         0         0  \n",
       "1           10.20        10.59         15.88         0         0  \n",
       "2           10.20        10.53         15.79         0         0  \n",
       "3            0.00        11.19         16.78         0         0  \n",
       "4           10.75         9.25         13.87         0         0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### % change in chess rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['r3r2'] = df_all.r3 / df_all.r2 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['r3r1'] = df_all.r3 / df_all.r1 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['allgames_change'] = df_all.allgames1yr/((df_all.allgames5yr - df_all.allgames1yr + 1)/4)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['fastevets_prop'] = df_all.fastevents / (df_all.fastevents + df_all.medevents + df_all.slowevents+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['medevents_prop'] = df_all.medevents / (df_all.fastevents + df_all.medevents + df_all.slowevents+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['slowevents_prop'] = df_all.slowevents / (df_all.fastevents + df_all.medevents + df_all.slowevents+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO region is discrete?? \n",
    "# last 8 are sq and cubed terms \n",
    "STANDARDIZE = ['age', 'region', 'nregions', 'memmonths', 'r1', 'r2', 'r3', 'r.quick', 'r.intl', \n",
    "               'allgames1yr', 'allgames5yr', 'fastevents', 'medevents', 'slowevents', 'nfloor', \n",
    "              'agesq', 'agecbd', 'allgames1yrsq', 'allgames1yrcbd', 'allgames5yrsq', 'allgames5yrcbd', 'memmonthssq', \n",
    "               'memmonthscbd', 'r3r2', 'r3r1', 'allgames_change', 'fastevets_prop', 'medevents_prop', 'slowevents_prop']\n",
    "\n",
    "\n",
    "INDICATORS = ['sex', 'mem_mag1', 'mem_mag2', 'hasemail', 'extra', 'intl', 'age.na', 'r1.na', 'r2.na', \n",
    "             'r3.na', 'r.quick.na', 'r.intl.na', 'mon_less30', 'mon_31', 'mon_32', 'mon_33', 'mon_34', \n",
    "             'mon_35', 'mon_36', 'mon_37_60', 'mon_61_84', 'mon_85_120', 'mon_121_263', 'mon_264_plus', \n",
    "             'games_0', 'games_1_5', 'games_6_10', 'games_11_20', 'games_21_34', 'games_35_49', 'games_50_plus', \n",
    "             'memtypeA', 'memtypeF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(STANDARDIZE) + len(INDICATORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ms_train_x = pd.read_csv('data/fromKen/stacking/l2_train.csv')\n",
    "# ms_train_y = pd.read_csv('data/fromKen/stacking/trainY.csv')\n",
    "ms_test_x = pd.read_csv('data/fromKen/stacking/l2_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43436, 3)\n",
      "(14479, 3)\n"
     ]
    }
   ],
   "source": [
    "print ms_train_x.shape\n",
    "# print ms_train_y.shape\n",
    "print ms_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAM_l1</th>\n",
       "      <th>GBX_l1</th>\n",
       "      <th>NN_l1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GAM_l1  GBX_l1  NN_l1\n",
       "0    0.94    0.95   0.94\n",
       "1    0.38    0.34   0.34\n",
       "2    0.67    0.72   0.66\n",
       "3    0.46    0.45   0.49\n",
       "4    0.86    0.87   0.86"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'GAM_l1', u'GBX_l1', u'NN_l1'], dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_train_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAM_l1</th>\n",
       "      <th>GBX_l1</th>\n",
       "      <th>NN_l1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GAM_l1  GBX_l1  NN_l1\n",
       "0    0.83    0.84   0.85\n",
       "1    0.68    0.61   0.66\n",
       "2    0.84    0.85   0.84\n",
       "3    0.53    0.57   0.54\n",
       "4    0.89    0.88   0.88"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'GAM_l1', u'GBX_l1', u'NN_l1'], dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_test_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all_stacking = pd.concat([ms_train_x, ms_test_x], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57915, 3)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_stacking.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57915, 62)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_all_stacking, df_all], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57915, 65)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Females\n",
    "importance_list = clfForest.feature_importances_\n",
    "name_list = all_features\n",
    "importance_list, name_list = zip(*sorted(zip(importance_list, name_list)))\n",
    "# just get top (in reverse order)\n",
    "top_imp = importance_list[-20:]\n",
    "top_names = name_list[-20:]\n",
    "plt.barh(range(len(top_names)),top_imp,align='center')\n",
    "plt.yticks(range(len(top_names)),top_names)\n",
    "plt.xlabel('Relative Importance in the Random Forest')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Relative importance of Top 20 Features for Females')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "track_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- df_all\n",
    "- df_all_stacking\n",
    "- test_idx\n",
    "- train_y\n",
    "- test_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52627\n",
      "Test set error = 0.53602\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51576\n",
      "Test set error = 0.53485\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49620\n",
      "Test set error = 0.54099\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47247\n",
      "Test set error = 0.53974\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52619\n",
      "Test set error = 0.53657\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51523\n",
      "Test set error = 0.53730\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49642\n",
      "Test set error = 0.53798\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47613\n",
      "Test set error = 0.53642\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52537\n",
      "Test set error = 0.53858\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51576\n",
      "Test set error = 0.53686\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50020\n",
      "Test set error = 0.53699\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47820\n",
      "Test set error = 0.53923\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52706\n",
      "Test set error = 0.53193\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51484\n",
      "Test set error = 0.53566\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49578\n",
      "Test set error = 0.54146\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47478\n",
      "Test set error = 0.53847\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52690\n",
      "Test set error = 0.53215\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51556\n",
      "Test set error = 0.53308\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49651\n",
      "Test set error = 0.54048\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47810\n",
      "Test set error = 0.53712\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52627\n",
      "Test set error = 0.53514\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51557\n",
      "Test set error = 0.53062\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49880\n",
      "Test set error = 0.53449\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47974\n",
      "Test set error = 0.53941\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52609\n",
      "Test set error = 0.53418\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51464\n",
      "Test set error = 0.53306\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49394\n",
      "Test set error = 0.54457\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47187\n",
      "Test set error = 0.54897\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52576\n",
      "Test set error = 0.53433\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51310\n",
      "Test set error = 0.54038\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49614\n",
      "Test set error = 0.54495\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47512\n",
      "Test set error = 0.53422\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52549\n",
      "Test set error = 0.53733\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51492\n",
      "Test set error = 0.53291\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49935\n",
      "Test set error = 0.53233\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47766\n",
      "Test set error = 0.54106\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51892\n",
      "Test set error = 0.53878\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49697\n",
      "Test set error = 0.54050\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.46909\n",
      "Test set error = 0.53648\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.42421\n",
      "Test set error = 0.55025\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51919\n",
      "Test set error = 0.53631\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49857\n",
      "Test set error = 0.54034\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.46825\n",
      "Test set error = 0.54359\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.42852\n",
      "Test set error = 0.55162\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51793\n",
      "Test set error = 0.54481\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49699\n",
      "Test set error = 0.54430\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.46993\n",
      "Test set error = 0.54062\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.43603\n",
      "Test set error = 0.55148\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51867\n",
      "Test set error = 0.53792\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49923\n",
      "Test set error = 0.53575\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.46818\n",
      "Test set error = 0.53198\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.42115\n",
      "Test set error = 0.54946\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51929\n",
      "Test set error = 0.53567\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49897\n",
      "Test set error = 0.53401\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.46711\n",
      "Test set error = 0.54794\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.43435\n",
      "Test set error = 0.54265\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52095\n",
      "Test set error = 0.52980\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50050\n",
      "Test set error = 0.53479\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.46738\n",
      "Test set error = 0.55121\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.43369\n",
      "Test set error = 0.54013\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51802\n",
      "Test set error = 0.53798\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49510\n",
      "Test set error = 0.54098\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.46523\n",
      "Test set error = 0.53475\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.42695\n",
      "Test set error = 0.53986\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51820\n",
      "Test set error = 0.53928\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49788\n",
      "Test set error = 0.53647\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.46675\n",
      "Test set error = 0.54156\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.42913\n",
      "Test set error = 0.54788\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51996\n",
      "Test set error = 0.53155\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49903\n",
      "Test set error = 0.53452\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47102\n",
      "Test set error = 0.54164\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.43194\n",
      "Test set error = 0.55524\n",
      "----------\n",
      "############\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "estimators = [250, 500] # default = 10\n",
    "features = [0.6, 0.75, 0.9] # default = 'sqrt'\n",
    "samples = [25, 35, 45] # default = 1\n",
    "max_depth = [2, 3, 4, 5]\n",
    "\n",
    "for e in estimators:\n",
    "    for f in features: \n",
    "        for s in samples: \n",
    "            for d in max_depth: \n",
    "                modelboost = GradientBoostingClassifier(n_estimators=e, max_features=f, min_samples_leaf=s, \n",
    "                                                   max_depth=d, random_state=616)\n",
    "                p2.get_pred_np(modelboost, df_all, train_y, 'RFBoost', track_dict=None, \n",
    "                            test_idx=test_idx, train_size=0.8, columns=None, parameters=None, \n",
    "                            score_func='log_loss', predict=False)\n",
    "\n",
    "\n",
    "# option to save fitted model\n",
    "# joblib.dump(model, 'models/baseline_logistic.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HERE NOW\n",
    "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
    "              max_depth=2, max_features=0.75, max_leaf_nodes=None,\n",
    "              min_samples_leaf=45, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "----------\n",
    "Training set error = 0.52095\n",
    "Test set error = 0.52980\n",
    "\n",
    "\n",
    "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
    "              max_depth=2, max_features=0.9, max_leaf_nodes=None,\n",
    "              min_samples_leaf=45, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "----------\n",
    "Training set error = 0.51996\n",
    "Test set error = 0.53155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_model = GradientBoostingClassifier(n_estimators=500, max_features=0.75, min_samples_leaf=45, max_depth=2, \n",
    "                                        random_state=616)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=2, max_features=0.75, max_leaf_nodes=None,\n",
       "              min_samples_leaf=45, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57915, 65)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_full = p2.fit_and_predict(full_model, df_all, train_y, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14479,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52170157753956758"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(train_y, full_model.predict_proba(df_all[:test_idx])[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p2.write_to_file('predictions/stacking_gbx_all_features.csv', pred_full, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAFtCAYAAADh6assAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1124a0090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# HERE NOW\n",
    "importance_list = full_model.feature_importances_\n",
    "name_list = df_all.columns\n",
    "importance_list, name_list = zip(*sorted(zip(importance_list, name_list)))\n",
    "# just get top (in reverse order)\n",
    "top_imp = importance_list[-40:]\n",
    "top_names = name_list[-40:]\n",
    "plt.barh(range(len(top_names)),top_imp,align='center')\n",
    "plt.yticks(range(len(top_names)),top_names)\n",
    "plt.xlabel('Relative Importance in the Random Forest')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Relative importance of Top Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nfloor',\n",
       " 'mon_35',\n",
       " 'memtypeF',\n",
       " 'memtypeA',\n",
       " 'fastevents',\n",
       " 'allgames1yr',\n",
       " 'allgames1yrsq',\n",
       " 'allgames5yrcbd',\n",
       " 'allgames5yrsq',\n",
       " 'allgames1yrcbd',\n",
       " 'allgames5yr',\n",
       " 'age',\n",
       " 'slowevents',\n",
       " 'agecbd',\n",
       " 'agesq',\n",
       " 'medevents',\n",
       " 'r.intl',\n",
       " 'fastevets_prop',\n",
       " 'memmonths',\n",
       " 'memmonthssq',\n",
       " 'slowevents_prop',\n",
       " 'medevents_prop',\n",
       " 'memmonthscbd',\n",
       " 'r3',\n",
       " 'region',\n",
       " 'knnpreds',\n",
       " 'r2',\n",
       " 'r1',\n",
       " 'gampreds',\n",
       " 'r3r1',\n",
       " 'allgames_change',\n",
       " 'rf2preds',\n",
       " 'r.quick',\n",
       " 'r3r2',\n",
       " 'glmpreds',\n",
       " 'nn2preds',\n",
       " 'rf1preds',\n",
       " 'nn1preds',\n",
       " 'svmpreds',\n",
       " 'gbpolypreds')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52820\n",
      "Test set error = 0.53683\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52239\n",
      "Test set error = 0.54181\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51756\n",
      "Test set error = 0.53481\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52816\n",
      "Test set error = 0.53892\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52270\n",
      "Test set error = 0.54298\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51868\n",
      "Test set error = 0.53541\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52782\n",
      "Test set error = 0.54060\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52541\n",
      "Test set error = 0.53366\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51870\n",
      "Test set error = 0.53765\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52812\n",
      "Test set error = 0.53495\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52253\n",
      "Test set error = 0.53670\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51673\n",
      "Test set error = 0.53394\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52731\n",
      "Test set error = 0.53912\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52261\n",
      "Test set error = 0.53883\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51612\n",
      "Test set error = 0.54446\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52723\n",
      "Test set error = 0.54023\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52402\n",
      "Test set error = 0.53659\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51621\n",
      "Test set error = 0.54478\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52891\n",
      "Test set error = 0.53184\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52283\n",
      "Test set error = 0.53780\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51776\n",
      "Test set error = 0.53263\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.53040\n",
      "Test set error = 0.52683\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52375\n",
      "Test set error = 0.53451\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51818\n",
      "Test set error = 0.53354\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52667\n",
      "Test set error = 0.54122\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52415\n",
      "Test set error = 0.53544\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51914\n",
      "Test set error = 0.53541\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52005\n",
      "Test set error = 0.53983\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51078\n",
      "Test set error = 0.54104\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50148\n",
      "Test set error = 0.53202\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51793\n",
      "Test set error = 0.55049\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51237\n",
      "Test set error = 0.54311\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50366\n",
      "Test set error = 0.53431\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52115\n",
      "Test set error = 0.53914\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51670\n",
      "Test set error = 0.52702\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50285\n",
      "Test set error = 0.54578\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51920\n",
      "Test set error = 0.53599\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51029\n",
      "Test set error = 0.53527\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49721\n",
      "Test set error = 0.53981\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51859\n",
      "Test set error = 0.54021\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51060\n",
      "Test set error = 0.53996\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50066\n",
      "Test set error = 0.53984\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52294\n",
      "Test set error = 0.52809\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51179\n",
      "Test set error = 0.53664\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50246\n",
      "Test set error = 0.53767\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51822\n",
      "Test set error = 0.54351\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50699\n",
      "Test set error = 0.54467\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49743\n",
      "Test set error = 0.53926\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52077\n",
      "Test set error = 0.53449\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51004\n",
      "Test set error = 0.53969\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50184\n",
      "Test set error = 0.53962\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52126\n",
      "Test set error = 0.53372\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51052\n",
      "Test set error = 0.54231\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50494\n",
      "Test set error = 0.53121\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51130\n",
      "Test set error = 0.53446\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49334\n",
      "Test set error = 0.54522\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47504\n",
      "Test set error = 0.54658\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51290\n",
      "Test set error = 0.53715\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49682\n",
      "Test set error = 0.54561\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48343\n",
      "Test set error = 0.54007\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51138\n",
      "Test set error = 0.54400\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49947\n",
      "Test set error = 0.54518\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48738\n",
      "Test set error = 0.54387\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50749\n",
      "Test set error = 0.54115\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48996\n",
      "Test set error = 0.54332\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47028\n",
      "Test set error = 0.55325\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50854\n",
      "Test set error = 0.54511\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49248\n",
      "Test set error = 0.54678\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47749\n",
      "Test set error = 0.54684\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51028\n",
      "Test set error = 0.54333\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49626\n",
      "Test set error = 0.54345\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48268\n",
      "Test set error = 0.54551\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50779\n",
      "Test set error = 0.54062\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49009\n",
      "Test set error = 0.54687\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47241\n",
      "Test set error = 0.54547\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51020\n",
      "Test set error = 0.53804\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49609\n",
      "Test set error = 0.53835\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47865\n",
      "Test set error = 0.55079\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51121\n",
      "Test set error = 0.53697\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49825\n",
      "Test set error = 0.53933\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48649\n",
      "Test set error = 0.53622\n",
      "----------\n",
      "############\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "estimators = [100, 250, 500] # default = 10\n",
    "features = [0.6, 0.75, 0.9] # default = 'sqrt'\n",
    "samples = [25, 35, 45] # default = 1\n",
    "max_depth = [3, 4, 5]\n",
    "\n",
    "for e in estimators:\n",
    "    for f in features: \n",
    "        for s in samples: \n",
    "            for d in max_depth: \n",
    "                modelboost = GradientBoostingClassifier(n_estimators=e, max_features=f, min_samples_leaf=s, \n",
    "                                                   max_depth=d, random_state=1004)\n",
    "                p2.get_pred_np(modelboost, df_all_stacking, train_y, 'RFBoost', track_dict=None, \n",
    "                            test_idx=test_idx, train_size=0.8, columns=None, parameters=None, \n",
    "                            score_func='log_loss', predict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HERE NOW\n",
    "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
    "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
    "              min_samples_leaf=35, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "----------\n",
    "Training set error = 0.53040\n",
    "Test set error = 0.52683\n",
    "\n",
    "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
    "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
    "              min_samples_leaf=45, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
    "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "----------\n",
    "Training set error = 0.51670\n",
    "Test set error = 0.52702\n",
    "\n",
    "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
    "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
    "              min_samples_leaf=45, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
    "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "----------\n",
    "Training set error = 0.52294\n",
    "Test set error = 0.52809"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_stacked2 = GradientBoostingClassifier(n_estimators=100, max_features=0.9, min_samples_leaf=35, max_depth=3, \n",
    "                                        random_state=1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO HERE NOW\n",
    "pred_stacked = p2.fit_and_predict(model_stacked2, df_all_stacking, train_y, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57915, 3)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_stacking.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14479,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52926730761224206"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(train_y, model_stacked2.predict_proba(df_all_stacking[:test_idx])[:, 1])\n",
    "# validation 0.52683\n",
    "# Kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
       "              min_samples_leaf=35, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=1004, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stacked2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p2.write_to_file('predictions/stacking2ndorder_gbx_no_features.csv', pred_stacked, test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just top 5 features + Model\n",
    "\n",
    "- age, memmonths, R3 (and R3.na), allgames1yr, hasemail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all_top5 = df_all[['GAM_l1', 'GBX_l1', 'NN_l1', 'age', 'memmonths', 'r3', 'r3.na', 'allgames1yr', 'hasemail']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'GAM_l1', u'GBX_l1', u'NN_l1', u'age', u'memmonths', u'r3', u'r3.na', u'allgames1yr', u'hasemail'], dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_top5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57915, 9)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_top5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52670\n",
      "Test set error = 0.53716\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52047\n",
      "Test set error = 0.53773\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51141\n",
      "Test set error = 0.53586\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52679\n",
      "Test set error = 0.53699\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52047\n",
      "Test set error = 0.53950\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51120\n",
      "Test set error = 0.54353\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52618\n",
      "Test set error = 0.54199\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52301\n",
      "Test set error = 0.53133\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51379\n",
      "Test set error = 0.53494\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52639\n",
      "Test set error = 0.53969\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51963\n",
      "Test set error = 0.53939\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51049\n",
      "Test set error = 0.53992\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52513\n",
      "Test set error = 0.54497\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52172\n",
      "Test set error = 0.53521\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51330\n",
      "Test set error = 0.53354\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52887\n",
      "Test set error = 0.52944\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52260\n",
      "Test set error = 0.53139\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51309\n",
      "Test set error = 0.53980\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52771\n",
      "Test set error = 0.53395\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52151\n",
      "Test set error = 0.52952\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50861\n",
      "Test set error = 0.54392\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52756\n",
      "Test set error = 0.53390\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51972\n",
      "Test set error = 0.54008\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51072\n",
      "Test set error = 0.54095\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52753\n",
      "Test set error = 0.53501\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52089\n",
      "Test set error = 0.54179\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51519\n",
      "Test set error = 0.52831\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51977\n",
      "Test set error = 0.53162\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50525\n",
      "Test set error = 0.54174\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48470\n",
      "Test set error = 0.54299\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51985\n",
      "Test set error = 0.53255\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50718\n",
      "Test set error = 0.53828\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48817\n",
      "Test set error = 0.54426\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51775\n",
      "Test set error = 0.54180\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50840\n",
      "Test set error = 0.53480\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49389\n",
      "Test set error = 0.52958\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51822\n",
      "Test set error = 0.53702\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50091\n",
      "Test set error = 0.55072\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48840\n",
      "Test set error = 0.53855\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51833\n",
      "Test set error = 0.53735\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50764\n",
      "Test set error = 0.53554\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49012\n",
      "Test set error = 0.54298\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51973\n",
      "Test set error = 0.53421\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50311\n",
      "Test set error = 0.54921\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49184\n",
      "Test set error = 0.53928\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51859\n",
      "Test set error = 0.53988\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50400\n",
      "Test set error = 0.54170\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48535\n",
      "Test set error = 0.54077\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51853\n",
      "Test set error = 0.53292\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50706\n",
      "Test set error = 0.52862\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48697\n",
      "Test set error = 0.54231\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51930\n",
      "Test set error = 0.53753\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50587\n",
      "Test set error = 0.53829\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48886\n",
      "Test set error = 0.54411\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50710\n",
      "Test set error = 0.53802\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48242\n",
      "Test set error = 0.54202\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.45378\n",
      "Test set error = 0.53527\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50600\n",
      "Test set error = 0.54292\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48627\n",
      "Test set error = 0.53530\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.45928\n",
      "Test set error = 0.54076\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50671\n",
      "Test set error = 0.54609\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48830\n",
      "Test set error = 0.54250\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.46158\n",
      "Test set error = 0.55076\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50488\n",
      "Test set error = 0.54121\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48072\n",
      "Test set error = 0.54122\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.44995\n",
      "Test set error = 0.54852\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50586\n",
      "Test set error = 0.54172\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48344\n",
      "Test set error = 0.54363\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.45759\n",
      "Test set error = 0.54572\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50718\n",
      "Test set error = 0.53915\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48624\n",
      "Test set error = 0.54156\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.46260\n",
      "Test set error = 0.54656\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50239\n",
      "Test set error = 0.54646\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47923\n",
      "Test set error = 0.53853\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.44662\n",
      "Test set error = 0.55606\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50638\n",
      "Test set error = 0.53824\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48465\n",
      "Test set error = 0.53210\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.45635\n",
      "Test set error = 0.54423\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50738\n",
      "Test set error = 0.53538\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48259\n",
      "Test set error = 0.55156\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.46052\n",
      "Test set error = 0.54231\n",
      "----------\n",
      "############\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "estimators = [100, 250, 500] # default = 10\n",
    "features = [0.6, 0.75, 0.9] # default = 'sqrt'\n",
    "samples = [25, 35, 45] # default = 1\n",
    "max_depth = [3, 4, 5]\n",
    "\n",
    "for e in estimators:\n",
    "    for f in features: \n",
    "        for s in samples: \n",
    "            for d in max_depth: \n",
    "                modelboost = GradientBoostingClassifier(n_estimators=e, max_features=f, min_samples_leaf=s, \n",
    "                                                   max_depth=d, random_state=823)\n",
    "                p2.get_pred_np(modelboost, df_all_top5, train_y, 'RFBoost', track_dict=None, \n",
    "                            test_idx=test_idx, train_size=0.8, columns=None, parameters=None, \n",
    "                            score_func='log_loss', predict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO HERE NOW\n",
    "\n",
    "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
    "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
    "              min_samples_leaf=45, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "----------\n",
    "Training set error = 0.51519\n",
    "Test set error = 0.52831\n",
    "\n",
    "\n",
    "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
    "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
    "              min_samples_leaf=35, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
    "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "----------\n",
    "Training set error = 0.50706\n",
    "Test set error = 0.52862\n",
    "\n",
    "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
    "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
    "              min_samples_leaf=45, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "----------\n",
    "Training set error = 0.52887\n",
    "Test set error = 0.52944\n",
    "\n",
    "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
    "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
    "              min_samples_leaf=25, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "              presort='auto', random_state=823, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "----------\n",
    "Training set error = 0.52151\n",
    "Test set error = 0.52952"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('age.na',\n",
       " 'games_0',\n",
       " 'games_11_20',\n",
       " 'games_21_34',\n",
       " 'games_35_49',\n",
       " 'games_50_plus',\n",
       " 'games_6_10',\n",
       " 'mem_mag2',\n",
       " 'mon_264_plus',\n",
       " 'mon_31',\n",
       " 'mon_33',\n",
       " 'mon_36',\n",
       " 'mon_37_60',\n",
       " 'mon_61_84',\n",
       " 'mon_less30',\n",
       " 'r.intl.na',\n",
       " 'r.quick.na',\n",
       " 'r1.na',\n",
       " 'r2.na',\n",
       " 'r3.na',\n",
       " 'mon_34',\n",
       " 'hasemail',\n",
       " 'mon_121_263',\n",
       " 'mon_35',\n",
       " 'mon_85_120',\n",
       " 'extra',\n",
       " 'allgames5yrcbd',\n",
       " 'nregions',\n",
       " 'sex',\n",
       " 'games_1_5',\n",
       " 'memtypeF',\n",
       " 'intl',\n",
       " 'mon_32',\n",
       " 'memtypeA',\n",
       " 'fastevents',\n",
       " 'allgames5yr',\n",
       " 'mem_mag1',\n",
       " 'nfloor',\n",
       " 'allgames5yrsq',\n",
       " 'allgames1yr',\n",
       " 'allgames1yrsq',\n",
       " 'agecbd',\n",
       " 'allgames1yrcbd',\n",
       " 'slowevents',\n",
       " 'r.intl',\n",
       " 'age',\n",
       " 'agesq',\n",
       " 'memmonths',\n",
       " 'memmonthssq',\n",
       " 'memmonthscbd',\n",
       " 'r3',\n",
       " 'fastevets_prop',\n",
       " 'slowevents_prop',\n",
       " 'medevents',\n",
       " 'medevents_prop',\n",
       " 'r1',\n",
       " 'r3r1',\n",
       " 'region',\n",
       " 'r.quick',\n",
       " 'GBX_l1',\n",
       " 'r2',\n",
       " 'allgames_change',\n",
       " 'r3r2',\n",
       " 'GAM_l1',\n",
       " 'NN_l1')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('r1',\n",
       " 'r3r1',\n",
       " 'region',\n",
       " 'r.quick',\n",
       " 'GBX_l1',\n",
       " 'r2',\n",
       " 'allgames_change',\n",
       " 'r3r2',\n",
       " 'GAM_l1',\n",
       " 'NN_l1')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_names[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glmpreds</th>\n",
       "      <th>gampreds</th>\n",
       "      <th>rf1preds</th>\n",
       "      <th>rf2preds</th>\n",
       "      <th>nn1preds</th>\n",
       "      <th>nn2preds</th>\n",
       "      <th>gbpolypreds</th>\n",
       "      <th>svmpreds</th>\n",
       "      <th>knnpreds</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>age.na</th>\n",
       "      <th>r1.na</th>\n",
       "      <th>r2.na</th>\n",
       "      <th>r3.na</th>\n",
       "      <th>r.quick.na</th>\n",
       "      <th>r.intl.na</th>\n",
       "      <th>mon_less30</th>\n",
       "      <th>mon_31</th>\n",
       "      <th>mon_32</th>\n",
       "      <th>mon_33</th>\n",
       "      <th>mon_34</th>\n",
       "      <th>mon_35</th>\n",
       "      <th>mon_36</th>\n",
       "      <th>mon_37_60</th>\n",
       "      <th>mon_61_84</th>\n",
       "      <th>mon_85_120</th>\n",
       "      <th>mon_121_263</th>\n",
       "      <th>mon_264_plus</th>\n",
       "      <th>games_0</th>\n",
       "      <th>games_1_5</th>\n",
       "      <th>games_6_10</th>\n",
       "      <th>games_11_20</th>\n",
       "      <th>games_21_34</th>\n",
       "      <th>games_35_49</th>\n",
       "      <th>games_50_plus</th>\n",
       "      <th>agesq</th>\n",
       "      <th>agecbd</th>\n",
       "      <th>allgames1yrsq</th>\n",
       "      <th>allgames1yrcbd</th>\n",
       "      <th>allgames5yrsq</th>\n",
       "      <th>allgames5yrcbd</th>\n",
       "      <th>memmonthssq</th>\n",
       "      <th>memmonthscbd</th>\n",
       "      <th>memtypeA</th>\n",
       "      <th>memtypeF</th>\n",
       "      <th>r3r2</th>\n",
       "      <th>r3r1</th>\n",
       "      <th>allgames_change</th>\n",
       "      <th>fastevets_prop</th>\n",
       "      <th>medevents_prop</th>\n",
       "      <th>slowevents_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.92</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>1557.56</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.99</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.48</td>\n",
       "      <td>61.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2178.00</td>\n",
       "      <td>2215.00</td>\n",
       "      <td>2291.00</td>\n",
       "      <td>2932.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.25</td>\n",
       "      <td>12.38</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.59</td>\n",
       "      <td>15.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>16.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>627.00</td>\n",
       "      <td>628.00</td>\n",
       "      <td>1362.00</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.53</td>\n",
       "      <td>15.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.17</td>\n",
       "      <td>115.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.40</td>\n",
       "      <td>47.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2600.00</td>\n",
       "      <td>2601.00</td>\n",
       "      <td>2602.00</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.74</td>\n",
       "      <td>11.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.19</td>\n",
       "      <td>16.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>11.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>464.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>958.00</td>\n",
       "      <td>1356.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.25</td>\n",
       "      <td>13.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   glmpreds  gampreds  rf1preds  rf2preds  nn1preds  nn2preds  gbpolypreds  svmpreds  knnpreds   age  sex  region  nregions  memmonths  mem_mag1  mem_mag2  hasemail      r1      r2      r3  r.quick  extra  intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  age.na  r1.na  r2.na  r3.na  r.quick.na  r.intl.na mon_less30 mon_31 mon_32 mon_33 mon_34 mon_35 mon_36 mon_37_60 mon_61_84 mon_85_120 mon_121_263 mon_264_plus games_0 games_1_5 games_6_10 games_11_20  \\\n",
       "0      0.94      0.94      1.00      1.00      0.95      0.95         0.94      0.78      0.92 11.00    0    0.12         1         19         0         0         0 1942.12 1811.61 1557.56  2007.74      0     0 3477.56            0            0           0          0           0       0       0      1      1      1           1          1       True  False  False  False  False  False  False     False     False      False       False        False    True     False      False       False   \n",
       "1      0.44      0.42      0.46      0.44      0.41      0.37         0.19      0.34      0.48 61.00    0    0.12         1        198         1         0         1 2178.00 2215.00 2291.00  2932.00      1     0 3477.56            4           29           1          0          10       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False      True      False       False   \n",
       "2      0.54      0.55      0.65      0.66      0.63      0.57         0.77      0.71      0.72 16.00    1    0.12         1        192         0         0         1  627.00  628.00 1362.00  2007.00      0     0 3477.56           29           29           0          4           1       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False      False       False   \n",
       "3      0.54      0.54      0.39      0.36      0.47      0.40         0.48      0.41      0.40 47.00    0    0.12         1        268         1         0         1 2600.00 2601.00 2602.00  2007.74      0     0 3477.56            0            0           0          0           0       0       0      0      0      0           1          1      False  False  False  False  False  False  False     False     False      False       False         True    True     False      False       False   \n",
       "4      0.89      0.88      0.83      0.83      0.83      0.85         0.82      0.82      0.68 11.00    1    0.12         1        101         0         0         0  464.00  466.00  958.00  1356.00      0     0 3477.56           12           35           0          8           0       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False       True       False        False   False     False      False        True   \n",
       "\n",
       "  games_21_34 games_35_49 games_50_plus  agesq  agecbd  allgames1yrsq  allgames1yrcbd  allgames5yrsq  allgames5yrcbd  memmonthssq  memmonthscbd  memtypeA  memtypeF  r3r2  r3r1  allgames_change  fastevets_prop  medevents_prop  slowevents_prop  \n",
       "0       False       False         False   4.97    7.45           0.00            0.00           0.00            0.00         5.99          8.99         0         0 -0.14 -0.20            -1.00            0.00            0.00             0.00  \n",
       "1       False       False          True   8.25   12.38           3.22            4.83           6.80           10.20        10.59         15.88         0         0  0.03  0.05            -0.38            0.09            0.00             0.91  \n",
       "2        True       False          True   5.67    8.50           6.80           10.20           6.80           10.20        10.53         15.79         0         0  1.17  1.17           115.00            0.00            0.80             0.20  \n",
       "3       False       False          True   7.74   11.61           0.00            0.00           0.00            0.00        11.19         16.78         0         0  0.00  0.00            -1.00            0.00            0.00             0.00  \n",
       "4       False       False          True   4.97    7.45           5.13            7.69           7.17           10.75         9.25         13.87         0         0  1.06  1.06             1.00            0.00            1.00             0.00  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slowevents_prop',\n",
       " 'medevents_prop',\n",
       " 'memmonthscbd',\n",
       " 'r3',\n",
       " 'region',\n",
       " 'knnpreds',\n",
       " 'r2',\n",
       " 'r1',\n",
       " 'gampreds',\n",
       " 'r3r1',\n",
       " 'allgames_change',\n",
       " 'rf2preds',\n",
       " 'r.quick',\n",
       " 'r3r2',\n",
       " 'glmpreds',\n",
       " 'nn2preds',\n",
       " 'rf1preds',\n",
       " 'nn1preds',\n",
       " 'svmpreds',\n",
       " 'gbpolypreds']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(top_names[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all_top10 = df_all[list(top_names[-10:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52630\n",
      "Test set error = 0.53893\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51850\n",
      "Test set error = 0.54301\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50994\n",
      "Test set error = 0.53828\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52920\n",
      "Test set error = 0.52811\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52047\n",
      "Test set error = 0.54129\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51344\n",
      "Test set error = 0.53080\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52500\n",
      "Test set error = 0.54721\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52064\n",
      "Test set error = 0.53611\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51368\n",
      "Test set error = 0.53463\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52652\n",
      "Test set error = 0.53842\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52090\n",
      "Test set error = 0.53266\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51197\n",
      "Test set error = 0.53529\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52822\n",
      "Test set error = 0.53046\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52031\n",
      "Test set error = 0.53929\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51060\n",
      "Test set error = 0.54103\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52744\n",
      "Test set error = 0.53604\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52212\n",
      "Test set error = 0.53432\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51271\n",
      "Test set error = 0.53505\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52358\n",
      "Test set error = 0.54745\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51820\n",
      "Test set error = 0.54392\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51142\n",
      "Test set error = 0.53419\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52731\n",
      "Test set error = 0.53449\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51887\n",
      "Test set error = 0.54277\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51025\n",
      "Test set error = 0.53928\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52786\n",
      "Test set error = 0.53266\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52132\n",
      "Test set error = 0.53718\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51080\n",
      "Test set error = 0.53870\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51865\n",
      "Test set error = 0.53177\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50042\n",
      "Test set error = 0.54524\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48811\n",
      "Test set error = 0.53828\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51791\n",
      "Test set error = 0.53684\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50721\n",
      "Test set error = 0.53037\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48993\n",
      "Test set error = 0.53156\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51944\n",
      "Test set error = 0.53362\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50690\n",
      "Test set error = 0.54260\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49024\n",
      "Test set error = 0.54177\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51555\n",
      "Test set error = 0.54492\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50496\n",
      "Test set error = 0.53677\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48497\n",
      "Test set error = 0.54098\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51885\n",
      "Test set error = 0.53327\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50514\n",
      "Test set error = 0.53626\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48621\n",
      "Test set error = 0.54614\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51816\n",
      "Test set error = 0.53884\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50574\n",
      "Test set error = 0.54413\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49149\n",
      "Test set error = 0.53786\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51894\n",
      "Test set error = 0.53078\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50144\n",
      "Test set error = 0.54378\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48804\n",
      "Test set error = 0.53335\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51801\n",
      "Test set error = 0.53475\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50232\n",
      "Test set error = 0.54177\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48564\n",
      "Test set error = 0.55051\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51881\n",
      "Test set error = 0.53637\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50518\n",
      "Test set error = 0.53518\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48692\n",
      "Test set error = 0.54816\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50281\n",
      "Test set error = 0.54200\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47981\n",
      "Test set error = 0.54959\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.44451\n",
      "Test set error = 0.55829\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50430\n",
      "Test set error = 0.53816\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48192\n",
      "Test set error = 0.54447\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.45600\n",
      "Test set error = 0.54605\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50743\n",
      "Test set error = 0.53384\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48663\n",
      "Test set error = 0.54007\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.45718\n",
      "Test set error = 0.55519\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50414\n",
      "Test set error = 0.53389\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47998\n",
      "Test set error = 0.53610\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.45120\n",
      "Test set error = 0.54262\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50466\n",
      "Test set error = 0.53844\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48108\n",
      "Test set error = 0.54208\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.45615\n",
      "Test set error = 0.55024\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50256\n",
      "Test set error = 0.55261\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47924\n",
      "Test set error = 0.55471\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.46242\n",
      "Test set error = 0.54671\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50223\n",
      "Test set error = 0.54099\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47739\n",
      "Test set error = 0.54725\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.44547\n",
      "Test set error = 0.55479\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50417\n",
      "Test set error = 0.53778\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48374\n",
      "Test set error = 0.53969\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.45571\n",
      "Test set error = 0.54418\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50540\n",
      "Test set error = 0.53991\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=4, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48370\n",
      "Test set error = 0.54193\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.45808\n",
      "Test set error = 0.55243\n",
      "----------\n",
      "############\n"
     ]
    }
   ],
   "source": [
    "# HERE NOW\n",
    "# parameters\n",
    "estimators = [100, 250, 500] # default = 10\n",
    "features = [0.6, 0.75, 0.9] # default = 'sqrt'\n",
    "samples = [25, 35, 45] # default = 1\n",
    "max_depth = [3, 4, 5]\n",
    "\n",
    "for e in estimators:\n",
    "    for f in features: \n",
    "        for s in samples: \n",
    "            for d in max_depth: \n",
    "                model_top = GradientBoostingClassifier(n_estimators=e, max_features=f, min_samples_leaf=s, \n",
    "                                                   max_depth=d, random_state=616)\n",
    "                p2.get_pred_np(model_top, df_all_top10, train_y, 'RFBoost', track_dict=None, \n",
    "                            test_idx=test_idx, train_size=0.8, columns=None, parameters=None, \n",
    "                            score_func='log_loss', predict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO HERE NOW\n",
    "\n",
    "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
    "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
    "              min_samples_leaf=35, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "              presort='auto', random_state=616, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "----------\n",
    "Training set error = 0.52920\n",
    "Test set error = 0.52811"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
