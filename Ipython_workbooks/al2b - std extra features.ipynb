{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# true, then pred\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import preprocessing\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('notebook')\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sknn.mlp import Classifier, Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import amyutility as p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'amyutility' from 'amyutility.pyc'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43436, 23)\n",
      "(14479, 23)\n"
     ]
    }
   ],
   "source": [
    "print train.shape\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traink = pd.read_csv('data/fromKen/full_train_2.csv')\n",
    "testk = pd.read_csv('data/fromKen/full_test_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43436, 56)\n",
      "(14479, 55)\n"
     ]
    }
   ],
   "source": [
    "print traink.shape\n",
    "print testk.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memtype</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.00</td>\n",
       "      <td>M</td>\n",
       "      <td>reg127</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2024.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.00</td>\n",
       "      <td>M</td>\n",
       "      <td>reg142</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>258</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2753.00</td>\n",
       "      <td>2751.00</td>\n",
       "      <td>2709.00</td>\n",
       "      <td>3528.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>nan</td>\n",
       "      <td>10</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.00</td>\n",
       "      <td>M</td>\n",
       "      <td>reg104</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>28</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1668.00</td>\n",
       "      <td>2910.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>nan</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.00</td>\n",
       "      <td>M</td>\n",
       "      <td>reg112</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>14</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>741.00</td>\n",
       "      <td>1107.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>nan</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.00</td>\n",
       "      <td>F</td>\n",
       "      <td>reg106</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>131</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>359.00</td>\n",
       "      <td>325.00</td>\n",
       "      <td>531.00</td>\n",
       "      <td>654.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>nan</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age sex  region  nregions memtype  memmonths mem_mag1 mem_mag2 hasemail      r1      r2      r3  r.quick extra intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  Id\n",
       "0 29.00   M  reg127         1       N          2        Y        N        N     nan     nan 2024.00      nan     N    N     nan            0            0           0          0           0       0   1\n",
       "1 16.00   M  reg142         1       N        258        N        N        Y 2753.00 2751.00 2709.00  3528.00     N    N     nan           10          223           0         57           7       0   2\n",
       "2 22.00   M  reg104         1       N         28        N        N        Y     nan     nan 1668.00  2910.00     N    N     nan            6            6           2          1           0       0   3\n",
       "3 10.00   M  reg112         1       N         14        N        N        Y     nan     nan  741.00  1107.00     N    N     nan           13           13           0          2           1       0   4\n",
       "4 14.00   F  reg106         1       N        131        N        N        N  359.00  325.00  531.00   654.00     N    N     nan           14           57           0         16           1       0   5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'lapsed', u'age', u'sex', u'region', u'nregions', u'memtype', u'memmonths', u'mem_mag1', u'mem_mag2', u'hasemail', u'r1', u'r2', u'r3', u'r.quick', u'extra', u'intl', u'r.intl', u'allgames1yr', u'allgames5yr', u'fastevents', u'medevents', u'slowevents', u'nfloor'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Ken's Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'lapsed', u'age', u'sex', u'region', u'nregions', u'memtype', u'memmonths', u'mem_mag1', u'mem_mag2', u'hasemail', u'r1', u'r2', u'r3', u'r.quick', u'extra', u'intl', u'r.intl', u'allgames1yr', u'allgames5yr', u'fastevents', u'medevents', u'slowevents', u'nfloor', u'age.na', u'r1.na', u'r2.na', u'r3.na', u'r.quick.na', u'r.intl.na', u'mon_less30', u'mon_31', u'mon_32', u'mon_33', u'mon_34', u'mon_35', u'mon_36', u'mon_37_60', u'mon_61_84', u'mon_85_120', u'mon_121_263', u'mon_264_plus',\n",
       "       u'games_0', u'games_1_5', u'games_6_10', u'games_11_20', u'games_21_34', u'games_35_49', u'games_50_plus', u'agesq', u'agecbd', u'allgames1yrsq', u'allgames1yrcbd', u'allgames5yrsq', u'allgames5yrcbd', u'memmonthssq', u'memmonthscbd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traink.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'age', u'sex', u'region', u'nregions', u'memtype', u'memmonths', u'mem_mag1', u'mem_mag2', u'hasemail', u'r1', u'r2', u'r3', u'r.quick', u'extra', u'intl', u'r.intl', u'allgames1yr', u'allgames5yr', u'fastevents', u'medevents', u'slowevents', u'nfloor', u'age.na', u'r1.na', u'r2.na', u'r3.na', u'r.quick.na', u'r.intl.na', u'mon_less30', u'mon_31', u'mon_32', u'mon_33', u'mon_34', u'mon_35', u'mon_36', u'mon_37_60', u'mon_61_84', u'mon_85_120', u'mon_121_263', u'mon_264_plus',\n",
       "       u'games_0', u'games_1_5', u'games_6_10', u'games_11_20', u'games_21_34', u'games_35_49', u'games_50_plus', u'agesq', u'agecbd', u'allgames1yrsq', u'allgames1yrcbd', u'allgames5yrsq', u'allgames5yrcbd', u'memmonthssq', u'memmonthscbd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testk.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lapsed</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memtype</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>age.na</th>\n",
       "      <th>r1.na</th>\n",
       "      <th>r2.na</th>\n",
       "      <th>r3.na</th>\n",
       "      <th>r.quick.na</th>\n",
       "      <th>r.intl.na</th>\n",
       "      <th>mon_less30</th>\n",
       "      <th>mon_31</th>\n",
       "      <th>mon_32</th>\n",
       "      <th>mon_33</th>\n",
       "      <th>mon_34</th>\n",
       "      <th>mon_35</th>\n",
       "      <th>mon_36</th>\n",
       "      <th>mon_37_60</th>\n",
       "      <th>mon_61_84</th>\n",
       "      <th>mon_85_120</th>\n",
       "      <th>mon_121_263</th>\n",
       "      <th>mon_264_plus</th>\n",
       "      <th>games_0</th>\n",
       "      <th>games_1_5</th>\n",
       "      <th>games_6_10</th>\n",
       "      <th>games_11_20</th>\n",
       "      <th>games_21_34</th>\n",
       "      <th>games_35_49</th>\n",
       "      <th>games_50_plus</th>\n",
       "      <th>agesq</th>\n",
       "      <th>agecbd</th>\n",
       "      <th>allgames1yrsq</th>\n",
       "      <th>allgames1yrcbd</th>\n",
       "      <th>allgames5yrsq</th>\n",
       "      <th>allgames5yrcbd</th>\n",
       "      <th>memmonthssq</th>\n",
       "      <th>memmonthscbd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>11.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>1557.56</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.99</td>\n",
       "      <td>8.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>61.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>198</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2178.00</td>\n",
       "      <td>2215.00</td>\n",
       "      <td>2291.00</td>\n",
       "      <td>2932.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.25</td>\n",
       "      <td>12.38</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.59</td>\n",
       "      <td>15.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>16.00</td>\n",
       "      <td>F</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>192</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>627.00</td>\n",
       "      <td>628.00</td>\n",
       "      <td>1362.00</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.53</td>\n",
       "      <td>15.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>47.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>268</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2600.00</td>\n",
       "      <td>2601.00</td>\n",
       "      <td>2602.00</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.74</td>\n",
       "      <td>11.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.19</td>\n",
       "      <td>16.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y</td>\n",
       "      <td>11.00</td>\n",
       "      <td>F</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>464.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>958.00</td>\n",
       "      <td>1356.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.25</td>\n",
       "      <td>13.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lapsed   age sex  region  nregions memtype  memmonths mem_mag1 mem_mag2 hasemail      r1      r2      r3  r.quick extra intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  age.na  r1.na  r2.na  r3.na  r.quick.na  r.intl.na mon_less30 mon_31 mon_32 mon_33 mon_34 mon_35 mon_36 mon_37_60 mon_61_84 mon_85_120 mon_121_263 mon_264_plus games_0 games_1_5 games_6_10 games_11_20 games_21_34 games_35_49 games_50_plus  agesq  agecbd  allgames1yrsq  allgames1yrcbd  \\\n",
       "0      Y 11.00   M    0.12         1       N         19        N        N        N 1942.12 1811.61 1557.56  2007.74     N    N 3477.56            0            0           0          0           0       0       0      1      1      1           1          1       True  False  False  False  False  False  False     False     False      False       False        False    True     False      False       False       False       False         False   4.97    7.45           0.00            0.00   \n",
       "1      N 61.00   M    0.12         1       N        198        Y        N        Y 2178.00 2215.00 2291.00  2932.00     Y    N 3477.56            4           29           1          0          10       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False      True      False       False       False       False          True   8.25   12.38           3.22            4.83   \n",
       "2      Y 16.00   F    0.12         1       N        192        N        N        Y  627.00  628.00 1362.00  2007.00     N    N 3477.56           29           29           0          4           1       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False      False       False        True       False          True   5.67    8.50           6.80           10.20   \n",
       "3      Y 47.00   M    0.12         1       N        268        Y        N        Y 2600.00 2601.00 2602.00  2007.74     N    N 3477.56            0            0           0          0           0       0       0      0      0      0           1          1      False  False  False  False  False  False  False     False     False      False       False         True    True     False      False       False       False       False          True   7.74   11.61           0.00            0.00   \n",
       "4      Y 11.00   F    0.12         1       N        101        N        N        N  464.00  466.00  958.00  1356.00     N    N 3477.56           12           35           0          8           0       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False       True       False        False   False     False      False        True       False       False          True   4.97    7.45           5.13            7.69   \n",
       "\n",
       "   allgames5yrsq  allgames5yrcbd  memmonthssq  memmonthscbd  \n",
       "0           0.00            0.00         5.99          8.99  \n",
       "1           6.80           10.20        10.59         15.88  \n",
       "2           6.80           10.20        10.53         15.79  \n",
       "3           0.00            0.00        11.19         16.78  \n",
       "4           7.17           10.75         9.25         13.87  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traink.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memtype</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>age.na</th>\n",
       "      <th>r1.na</th>\n",
       "      <th>r2.na</th>\n",
       "      <th>r3.na</th>\n",
       "      <th>r.quick.na</th>\n",
       "      <th>r.intl.na</th>\n",
       "      <th>mon_less30</th>\n",
       "      <th>mon_31</th>\n",
       "      <th>mon_32</th>\n",
       "      <th>mon_33</th>\n",
       "      <th>mon_34</th>\n",
       "      <th>mon_35</th>\n",
       "      <th>mon_36</th>\n",
       "      <th>mon_37_60</th>\n",
       "      <th>mon_61_84</th>\n",
       "      <th>mon_85_120</th>\n",
       "      <th>mon_121_263</th>\n",
       "      <th>mon_264_plus</th>\n",
       "      <th>games_0</th>\n",
       "      <th>games_1_5</th>\n",
       "      <th>games_6_10</th>\n",
       "      <th>games_11_20</th>\n",
       "      <th>games_21_34</th>\n",
       "      <th>games_35_49</th>\n",
       "      <th>games_50_plus</th>\n",
       "      <th>agesq</th>\n",
       "      <th>agecbd</th>\n",
       "      <th>allgames1yrsq</th>\n",
       "      <th>allgames1yrcbd</th>\n",
       "      <th>allgames5yrsq</th>\n",
       "      <th>allgames5yrcbd</th>\n",
       "      <th>memmonthssq</th>\n",
       "      <th>memmonthscbd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>2024.00</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>258</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2753.00</td>\n",
       "      <td>2751.00</td>\n",
       "      <td>2709.00</td>\n",
       "      <td>3528.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>10</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.50</td>\n",
       "      <td>4.80</td>\n",
       "      <td>7.19</td>\n",
       "      <td>10.82</td>\n",
       "      <td>16.23</td>\n",
       "      <td>11.11</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>28</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>1668.00</td>\n",
       "      <td>2910.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.27</td>\n",
       "      <td>9.41</td>\n",
       "      <td>3.89</td>\n",
       "      <td>5.84</td>\n",
       "      <td>3.89</td>\n",
       "      <td>5.84</td>\n",
       "      <td>6.73</td>\n",
       "      <td>10.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>14</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>741.00</td>\n",
       "      <td>1107.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.80</td>\n",
       "      <td>7.19</td>\n",
       "      <td>5.28</td>\n",
       "      <td>7.92</td>\n",
       "      <td>5.28</td>\n",
       "      <td>7.92</td>\n",
       "      <td>5.42</td>\n",
       "      <td>8.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.00</td>\n",
       "      <td>F</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>131</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>359.00</td>\n",
       "      <td>325.00</td>\n",
       "      <td>531.00</td>\n",
       "      <td>654.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.42</td>\n",
       "      <td>8.12</td>\n",
       "      <td>5.42</td>\n",
       "      <td>8.12</td>\n",
       "      <td>8.12</td>\n",
       "      <td>12.18</td>\n",
       "      <td>9.77</td>\n",
       "      <td>14.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age sex  region  nregions memtype  memmonths mem_mag1 mem_mag2 hasemail      r1      r2      r3  r.quick extra intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  age.na  r1.na  r2.na  r3.na  r.quick.na  r.intl.na mon_less30 mon_31 mon_32 mon_33 mon_34 mon_35 mon_36 mon_37_60 mon_61_84 mon_85_120 mon_121_263 mon_264_plus games_0 games_1_5 games_6_10 games_11_20 games_21_34 games_35_49 games_50_plus  agesq  agecbd  allgames1yrsq  allgames1yrcbd  allgames5yrsq  \\\n",
       "0 29.00   M    0.11         1       N          2        Y        N        N 1942.12 1811.61 2024.00  2007.74     N    N 3477.56            0            0           0          0           0       0       0      1      1      0           1          1       True  False  False  False  False  False  False     False     False      False       False        False    True     False      False       False       False       False         False   6.80   10.20           0.00            0.00           0.00   \n",
       "1 16.00   M    0.02         1       N        258        N        N        Y 2753.00 2751.00 2709.00  3528.00     N    N 3477.56           10          223           0         57           7       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False       True       False       False       False          True   5.67    8.50           4.80            7.19          10.82   \n",
       "2 22.00   M    0.00         1       N         28        N        N        Y 1942.12 1811.61 1668.00  2910.00     N    N 3477.56            6            6           2          1           0       0       0      1      1      0           0          1       True  False  False  False  False  False  False     False     False      False       False        False   False     False       True       False       False       False         False   6.27    9.41           3.89            5.84           3.89   \n",
       "3 10.00   M    0.12         1       N         14        N        N        Y 1942.12 1811.61  741.00  1107.00     N    N 3477.56           13           13           0          2           1       0       0      1      1      0           0          1       True  False  False  False  False  False  False     False     False      False       False        False   False     False      False        True       False       False         False   4.80    7.19           5.28            7.92           5.28   \n",
       "4 14.00   F    0.04         1       N        131        N        N        N  359.00  325.00  531.00   654.00     N    N 3477.56           14           57           0         16           1       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False      False        True       False       False          True   5.42    8.12           5.42            8.12           8.12   \n",
       "\n",
       "   allgames5yrcbd  memmonthssq  memmonthscbd  \n",
       "0            0.00         2.20          3.30  \n",
       "1           16.23        11.11         16.67  \n",
       "2            5.84         6.73         10.10  \n",
       "3            7.92         5.42          8.12  \n",
       "4           12.18         9.77         14.65  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traink_y = traink[['lapsed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lapsed\n",
       "0      Y\n",
       "1      N\n",
       "2      Y\n",
       "3      Y\n",
       "4      Y"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traink_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traink_x = traink.drop('lapsed', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43436, 55)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traink_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memtype</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>age.na</th>\n",
       "      <th>r1.na</th>\n",
       "      <th>r2.na</th>\n",
       "      <th>r3.na</th>\n",
       "      <th>r.quick.na</th>\n",
       "      <th>r.intl.na</th>\n",
       "      <th>mon_less30</th>\n",
       "      <th>mon_31</th>\n",
       "      <th>mon_32</th>\n",
       "      <th>mon_33</th>\n",
       "      <th>mon_34</th>\n",
       "      <th>mon_35</th>\n",
       "      <th>mon_36</th>\n",
       "      <th>mon_37_60</th>\n",
       "      <th>mon_61_84</th>\n",
       "      <th>mon_85_120</th>\n",
       "      <th>mon_121_263</th>\n",
       "      <th>mon_264_plus</th>\n",
       "      <th>games_0</th>\n",
       "      <th>games_1_5</th>\n",
       "      <th>games_6_10</th>\n",
       "      <th>games_11_20</th>\n",
       "      <th>games_21_34</th>\n",
       "      <th>games_35_49</th>\n",
       "      <th>games_50_plus</th>\n",
       "      <th>agesq</th>\n",
       "      <th>agecbd</th>\n",
       "      <th>allgames1yrsq</th>\n",
       "      <th>allgames1yrcbd</th>\n",
       "      <th>allgames5yrsq</th>\n",
       "      <th>allgames5yrcbd</th>\n",
       "      <th>memmonthssq</th>\n",
       "      <th>memmonthscbd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>1557.56</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.99</td>\n",
       "      <td>8.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>198</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2178.00</td>\n",
       "      <td>2215.00</td>\n",
       "      <td>2291.00</td>\n",
       "      <td>2932.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.25</td>\n",
       "      <td>12.38</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.59</td>\n",
       "      <td>15.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.00</td>\n",
       "      <td>F</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>192</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>627.00</td>\n",
       "      <td>628.00</td>\n",
       "      <td>1362.00</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.53</td>\n",
       "      <td>15.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>268</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2600.00</td>\n",
       "      <td>2601.00</td>\n",
       "      <td>2602.00</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.74</td>\n",
       "      <td>11.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.19</td>\n",
       "      <td>16.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.00</td>\n",
       "      <td>F</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>464.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>958.00</td>\n",
       "      <td>1356.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.25</td>\n",
       "      <td>13.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age sex  region  nregions memtype  memmonths mem_mag1 mem_mag2 hasemail      r1      r2      r3  r.quick extra intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  age.na  r1.na  r2.na  r3.na  r.quick.na  r.intl.na mon_less30 mon_31 mon_32 mon_33 mon_34 mon_35 mon_36 mon_37_60 mon_61_84 mon_85_120 mon_121_263 mon_264_plus games_0 games_1_5 games_6_10 games_11_20 games_21_34 games_35_49 games_50_plus  agesq  agecbd  allgames1yrsq  allgames1yrcbd  allgames5yrsq  \\\n",
       "0 11.00   M    0.12         1       N         19        N        N        N 1942.12 1811.61 1557.56  2007.74     N    N 3477.56            0            0           0          0           0       0       0      1      1      1           1          1       True  False  False  False  False  False  False     False     False      False       False        False    True     False      False       False       False       False         False   4.97    7.45           0.00            0.00           0.00   \n",
       "1 61.00   M    0.12         1       N        198        Y        N        Y 2178.00 2215.00 2291.00  2932.00     Y    N 3477.56            4           29           1          0          10       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False      True      False       False       False       False          True   8.25   12.38           3.22            4.83           6.80   \n",
       "2 16.00   F    0.12         1       N        192        N        N        Y  627.00  628.00 1362.00  2007.00     N    N 3477.56           29           29           0          4           1       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False      False       False        True       False          True   5.67    8.50           6.80           10.20           6.80   \n",
       "3 47.00   M    0.12         1       N        268        Y        N        Y 2600.00 2601.00 2602.00  2007.74     N    N 3477.56            0            0           0          0           0       0       0      0      0      0           1          1      False  False  False  False  False  False  False     False     False      False       False         True    True     False      False       False       False       False          True   7.74   11.61           0.00            0.00           0.00   \n",
       "4 11.00   F    0.12         1       N        101        N        N        N  464.00  466.00  958.00  1356.00     N    N 3477.56           12           35           0          8           0       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False       True       False        False   False     False      False        True       False       False          True   4.97    7.45           5.13            7.69           7.17   \n",
       "\n",
       "   allgames5yrcbd  memmonthssq  memmonthscbd  \n",
       "0            0.00         5.99          8.99  \n",
       "1           10.20        10.59         15.88  \n",
       "2           10.20        10.53         15.79  \n",
       "3            0.00        11.19         16.78  \n",
       "4           10.75         9.25         13.87  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traink_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = (traink_y.lapsed.values=='Y')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key train_y\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     2,     3, ..., 14477, 14478, 14479])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key test_ids: for writing to predictions\n",
    "test_ids = test.Id.values\n",
    "test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# key df_all: combine test and train into df_all, test_idx \n",
    "test_idx = traink_x.shape[0]\n",
    "df_all = pd.concat((traink_x, testk), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57915, 55)\n",
      "43436\n"
     ]
    }
   ],
   "source": [
    "print df_all.shape\n",
    "print test_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key: \n",
    "- df_all\n",
    "- test_idx\n",
    "- train_y\n",
    "- test_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Types and Convert\n",
    "\n",
    "- need to convert sex, memtype, mem_mag1, mem_mag2, hasemail, extra, intl\n",
    "- Can leave bools alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CONVERT = ['sex', 'memtype', 'mem_mag1', 'mem_mag2', 'hasemail', 'extra', 'intl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sex\n",
    "\n",
    "- males 0\n",
    "- females 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAFeCAYAAACvnuTEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKABAcf4PyfuyvtiPZrgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10caf5a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mostly male (males 0, females 1)\n",
    "gender = df_all.groupby('sex').size().sort_values(ascending = True)/df_all.shape[0]*100\n",
    "gender.plot(kind='barh', title = 'Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memtype</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>age.na</th>\n",
       "      <th>r1.na</th>\n",
       "      <th>r2.na</th>\n",
       "      <th>r3.na</th>\n",
       "      <th>r.quick.na</th>\n",
       "      <th>r.intl.na</th>\n",
       "      <th>mon_less30</th>\n",
       "      <th>mon_31</th>\n",
       "      <th>mon_32</th>\n",
       "      <th>mon_33</th>\n",
       "      <th>mon_34</th>\n",
       "      <th>mon_35</th>\n",
       "      <th>mon_36</th>\n",
       "      <th>mon_37_60</th>\n",
       "      <th>mon_61_84</th>\n",
       "      <th>mon_85_120</th>\n",
       "      <th>mon_121_263</th>\n",
       "      <th>mon_264_plus</th>\n",
       "      <th>games_0</th>\n",
       "      <th>games_1_5</th>\n",
       "      <th>games_6_10</th>\n",
       "      <th>games_11_20</th>\n",
       "      <th>games_21_34</th>\n",
       "      <th>games_35_49</th>\n",
       "      <th>games_50_plus</th>\n",
       "      <th>agesq</th>\n",
       "      <th>agecbd</th>\n",
       "      <th>allgames1yrsq</th>\n",
       "      <th>allgames1yrcbd</th>\n",
       "      <th>allgames5yrsq</th>\n",
       "      <th>allgames5yrcbd</th>\n",
       "      <th>memmonthssq</th>\n",
       "      <th>memmonthscbd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>1557.56</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.99</td>\n",
       "      <td>8.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>198</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2178.00</td>\n",
       "      <td>2215.00</td>\n",
       "      <td>2291.00</td>\n",
       "      <td>2932.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.25</td>\n",
       "      <td>12.38</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.59</td>\n",
       "      <td>15.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.00</td>\n",
       "      <td>F</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>192</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>627.00</td>\n",
       "      <td>628.00</td>\n",
       "      <td>1362.00</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.53</td>\n",
       "      <td>15.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.00</td>\n",
       "      <td>M</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>268</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2600.00</td>\n",
       "      <td>2601.00</td>\n",
       "      <td>2602.00</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.74</td>\n",
       "      <td>11.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.19</td>\n",
       "      <td>16.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.00</td>\n",
       "      <td>F</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>464.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>958.00</td>\n",
       "      <td>1356.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.25</td>\n",
       "      <td>13.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age sex  region  nregions memtype  memmonths mem_mag1 mem_mag2 hasemail      r1      r2      r3  r.quick extra intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  age.na  r1.na  r2.na  r3.na  r.quick.na  r.intl.na mon_less30 mon_31 mon_32 mon_33 mon_34 mon_35 mon_36 mon_37_60 mon_61_84 mon_85_120 mon_121_263 mon_264_plus games_0 games_1_5 games_6_10 games_11_20 games_21_34 games_35_49 games_50_plus  agesq  agecbd  allgames1yrsq  allgames1yrcbd  allgames5yrsq  \\\n",
       "0 11.00   M    0.12         1       N         19        N        N        N 1942.12 1811.61 1557.56  2007.74     N    N 3477.56            0            0           0          0           0       0       0      1      1      1           1          1       True  False  False  False  False  False  False     False     False      False       False        False    True     False      False       False       False       False         False   4.97    7.45           0.00            0.00           0.00   \n",
       "1 61.00   M    0.12         1       N        198        Y        N        Y 2178.00 2215.00 2291.00  2932.00     Y    N 3477.56            4           29           1          0          10       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False      True      False       False       False       False          True   8.25   12.38           3.22            4.83           6.80   \n",
       "2 16.00   F    0.12         1       N        192        N        N        Y  627.00  628.00 1362.00  2007.00     N    N 3477.56           29           29           0          4           1       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False      False       False        True       False          True   5.67    8.50           6.80           10.20           6.80   \n",
       "3 47.00   M    0.12         1       N        268        Y        N        Y 2600.00 2601.00 2602.00  2007.74     N    N 3477.56            0            0           0          0           0       0       0      0      0      0           1          1      False  False  False  False  False  False  False     False     False      False       False         True    True     False      False       False       False       False          True   7.74   11.61           0.00            0.00           0.00   \n",
       "4 11.00   F    0.12         1       N        101        N        N        N  464.00  466.00  958.00  1356.00     N    N 3477.56           12           35           0          8           0       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False       True       False        False   False     False      False        True       False       False          True   4.97    7.45           5.13            7.69           7.17   \n",
       "\n",
       "   allgames5yrcbd  memmonthssq  memmonthscbd  \n",
       "0            0.00         5.99          8.99  \n",
       "1           10.20        10.59         15.88  \n",
       "2           10.20        10.53         15.79  \n",
       "3            0.00        11.19         16.78  \n",
       "4           10.75         9.25         13.87  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               float64\n",
       "sex                object\n",
       "region            float64\n",
       "nregions            int64\n",
       "memtype            object\n",
       "memmonths           int64\n",
       "mem_mag1           object\n",
       "mem_mag2           object\n",
       "hasemail           object\n",
       "r1                float64\n",
       "r2                float64\n",
       "r3                float64\n",
       "r.quick           float64\n",
       "extra              object\n",
       "intl               object\n",
       "r.intl            float64\n",
       "allgames1yr         int64\n",
       "allgames5yr         int64\n",
       "fastevents          int64\n",
       "medevents           int64\n",
       "slowevents          int64\n",
       "nfloor              int64\n",
       "age.na              int64\n",
       "r1.na               int64\n",
       "r2.na               int64\n",
       "r3.na               int64\n",
       "r.quick.na          int64\n",
       "r.intl.na           int64\n",
       "mon_less30           bool\n",
       "mon_31               bool\n",
       "mon_32               bool\n",
       "mon_33               bool\n",
       "mon_34               bool\n",
       "mon_35               bool\n",
       "mon_36               bool\n",
       "mon_37_60            bool\n",
       "mon_61_84            bool\n",
       "mon_85_120           bool\n",
       "mon_121_263          bool\n",
       "mon_264_plus         bool\n",
       "games_0              bool\n",
       "games_1_5            bool\n",
       "games_6_10           bool\n",
       "games_11_20          bool\n",
       "games_21_34          bool\n",
       "games_35_49          bool\n",
       "games_50_plus        bool\n",
       "agesq             float64\n",
       "agecbd            float64\n",
       "allgames1yrsq     float64\n",
       "allgames1yrcbd    float64\n",
       "allgames5yrsq     float64\n",
       "allgames5yrcbd    float64\n",
       "memmonthssq       float64\n",
       "memmonthscbd      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 M\n",
       "1                 M\n",
       "2                 F\n",
       "3                 M\n",
       "4                 F\n",
       "5                 F\n",
       "6                 M\n",
       "7                 M\n",
       "8                 M\n",
       "9                 M\n",
       "10                M\n",
       "11                M\n",
       "12                M\n",
       "13                M\n",
       "14                M\n",
       "15                F\n",
       "16                M\n",
       "17                M\n",
       "18                F\n",
       "19                M\n",
       "20                M\n",
       "21                F\n",
       "22                M\n",
       "23                M\n",
       "24                M\n",
       "25                M\n",
       "26                M\n",
       "27                M\n",
       "28                F\n",
       "29                M\n",
       "30                M\n",
       "31                M\n",
       "32                M\n",
       "33                F\n",
       "34                M\n",
       "35                M\n",
       "36                M\n",
       "37                M\n",
       "38                M\n",
       "39                F\n",
       "40                M\n",
       "41                M\n",
       "42                M\n",
       "43                F\n",
       "44                M\n",
       "45                M\n",
       "46                M\n",
       "47                M\n",
       "48                M\n",
       "49                M\n",
       "50                M\n",
       "51                M\n",
       "52                F\n",
       "53                M\n",
       "54                M\n",
       "55                F\n",
       "56                M\n",
       "57                M\n",
       "58                M\n",
       "59                M\n",
       "60                M\n",
       "61       Z_dummy_NA\n",
       "62                M\n",
       "63                M\n",
       "64                M\n",
       "65                M\n",
       "66                M\n",
       "67                M\n",
       "68                M\n",
       "69                M\n",
       "70                M\n",
       "71                M\n",
       "72                M\n",
       "73                M\n",
       "74                M\n",
       "75                M\n",
       "76                M\n",
       "77                M\n",
       "78                M\n",
       "79                M\n",
       "80       Z_dummy_NA\n",
       "81                M\n",
       "82                F\n",
       "83                M\n",
       "84                M\n",
       "85       Z_dummy_NA\n",
       "86                F\n",
       "87                M\n",
       "88                M\n",
       "89                M\n",
       "90                M\n",
       "91                M\n",
       "92                M\n",
       "93                M\n",
       "94                M\n",
       "95                M\n",
       "96                M\n",
       "97                M\n",
       "98                M\n",
       "99                M\n",
       "            ...    \n",
       "14379             M\n",
       "14380             M\n",
       "14381             M\n",
       "14382             M\n",
       "14383             M\n",
       "14384             F\n",
       "14385             M\n",
       "14386             M\n",
       "14387             M\n",
       "14388             M\n",
       "14389             M\n",
       "14390             M\n",
       "14391             M\n",
       "14392             M\n",
       "14393             M\n",
       "14394             M\n",
       "14395             M\n",
       "14396             M\n",
       "14397             M\n",
       "14398             M\n",
       "14399             M\n",
       "14400             M\n",
       "14401             M\n",
       "14402             M\n",
       "14403             M\n",
       "14404             M\n",
       "14405             M\n",
       "14406             F\n",
       "14407             M\n",
       "14408             M\n",
       "14409             F\n",
       "14410             M\n",
       "14411             M\n",
       "14412             M\n",
       "14413             M\n",
       "14414             M\n",
       "14415             M\n",
       "14416             M\n",
       "14417             M\n",
       "14418             M\n",
       "14419             M\n",
       "14420             M\n",
       "14421             F\n",
       "14422             M\n",
       "14423             M\n",
       "14424    Z_dummy_NA\n",
       "14425             M\n",
       "14426             F\n",
       "14427             M\n",
       "14428             M\n",
       "14429             M\n",
       "14430             M\n",
       "14431             F\n",
       "14432             M\n",
       "14433             M\n",
       "14434             M\n",
       "14435             M\n",
       "14436             M\n",
       "14437             M\n",
       "14438             M\n",
       "14439    Z_dummy_NA\n",
       "14440             M\n",
       "14441             M\n",
       "14442             M\n",
       "14443             M\n",
       "14444             M\n",
       "14445             M\n",
       "14446             M\n",
       "14447             M\n",
       "14448             M\n",
       "14449             F\n",
       "14450             M\n",
       "14451             M\n",
       "14452             M\n",
       "14453             M\n",
       "14454             M\n",
       "14455             M\n",
       "14456             M\n",
       "14457             F\n",
       "14458             M\n",
       "14459             M\n",
       "14460             M\n",
       "14461             M\n",
       "14462             M\n",
       "14463             M\n",
       "14464             M\n",
       "14465             M\n",
       "14466             F\n",
       "14467             M\n",
       "14468             M\n",
       "14469             F\n",
       "14470             M\n",
       "14471             M\n",
       "14472             M\n",
       "14473             F\n",
       "14474    Z_dummy_NA\n",
       "14475             F\n",
       "14476             M\n",
       "14477             M\n",
       "14478             M\n",
       "Name: sex, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.sex = (df_all.sex.values=='F')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memtype</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>age.na</th>\n",
       "      <th>r1.na</th>\n",
       "      <th>r2.na</th>\n",
       "      <th>r3.na</th>\n",
       "      <th>r.quick.na</th>\n",
       "      <th>r.intl.na</th>\n",
       "      <th>mon_less30</th>\n",
       "      <th>mon_31</th>\n",
       "      <th>mon_32</th>\n",
       "      <th>mon_33</th>\n",
       "      <th>mon_34</th>\n",
       "      <th>mon_35</th>\n",
       "      <th>mon_36</th>\n",
       "      <th>mon_37_60</th>\n",
       "      <th>mon_61_84</th>\n",
       "      <th>mon_85_120</th>\n",
       "      <th>mon_121_263</th>\n",
       "      <th>mon_264_plus</th>\n",
       "      <th>games_0</th>\n",
       "      <th>games_1_5</th>\n",
       "      <th>games_6_10</th>\n",
       "      <th>games_11_20</th>\n",
       "      <th>games_21_34</th>\n",
       "      <th>games_35_49</th>\n",
       "      <th>games_50_plus</th>\n",
       "      <th>agesq</th>\n",
       "      <th>agecbd</th>\n",
       "      <th>allgames1yrsq</th>\n",
       "      <th>allgames1yrcbd</th>\n",
       "      <th>allgames5yrsq</th>\n",
       "      <th>allgames5yrcbd</th>\n",
       "      <th>memmonthssq</th>\n",
       "      <th>memmonthscbd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>1557.56</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.99</td>\n",
       "      <td>8.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>198</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2178.00</td>\n",
       "      <td>2215.00</td>\n",
       "      <td>2291.00</td>\n",
       "      <td>2932.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.25</td>\n",
       "      <td>12.38</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.59</td>\n",
       "      <td>15.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>192</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>627.00</td>\n",
       "      <td>628.00</td>\n",
       "      <td>1362.00</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.53</td>\n",
       "      <td>15.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>268</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2600.00</td>\n",
       "      <td>2601.00</td>\n",
       "      <td>2602.00</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.74</td>\n",
       "      <td>11.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.19</td>\n",
       "      <td>16.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>101</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>464.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>958.00</td>\n",
       "      <td>1356.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.25</td>\n",
       "      <td>13.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  region  nregions memtype  memmonths mem_mag1 mem_mag2 hasemail      r1      r2      r3  r.quick extra intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  age.na  r1.na  r2.na  r3.na  r.quick.na  r.intl.na mon_less30 mon_31 mon_32 mon_33 mon_34 mon_35 mon_36 mon_37_60 mon_61_84 mon_85_120 mon_121_263 mon_264_plus games_0 games_1_5 games_6_10 games_11_20 games_21_34 games_35_49 games_50_plus  agesq  agecbd  allgames1yrsq  allgames1yrcbd  \\\n",
       "0 11.00    0    0.12         1       N         19        N        N        N 1942.12 1811.61 1557.56  2007.74     N    N 3477.56            0            0           0          0           0       0       0      1      1      1           1          1       True  False  False  False  False  False  False     False     False      False       False        False    True     False      False       False       False       False         False   4.97    7.45           0.00            0.00   \n",
       "1 61.00    0    0.12         1       N        198        Y        N        Y 2178.00 2215.00 2291.00  2932.00     Y    N 3477.56            4           29           1          0          10       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False      True      False       False       False       False          True   8.25   12.38           3.22            4.83   \n",
       "2 16.00    1    0.12         1       N        192        N        N        Y  627.00  628.00 1362.00  2007.00     N    N 3477.56           29           29           0          4           1       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False      False       False        True       False          True   5.67    8.50           6.80           10.20   \n",
       "3 47.00    0    0.12         1       N        268        Y        N        Y 2600.00 2601.00 2602.00  2007.74     N    N 3477.56            0            0           0          0           0       0       0      0      0      0           1          1      False  False  False  False  False  False  False     False     False      False       False         True    True     False      False       False       False       False          True   7.74   11.61           0.00            0.00   \n",
       "4 11.00    1    0.12         1       N        101        N        N        N  464.00  466.00  958.00  1356.00     N    N 3477.56           12           35           0          8           0       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False       True       False        False   False     False      False        True       False       False          True   4.97    7.45           5.13            7.69   \n",
       "\n",
       "   allgames5yrsq  allgames5yrcbd  memmonthssq  memmonthscbd  \n",
       "0           0.00            0.00         5.99          8.99  \n",
       "1           6.80           10.20        10.59         15.88  \n",
       "2           6.80           10.20        10.53         15.79  \n",
       "3           0.00            0.00        11.19         16.78  \n",
       "4           7.17           10.75         9.25         13.87  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### memtype\n",
    "- make Normal the reference category\n",
    "- memtypeA=1 for affiliate\n",
    "- memtypeF=1 for family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFeCAYAAACsH5cdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cbe2bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# membership types A, F, N \n",
    "memtype = df_all.groupby('memtype').size().sort_values(ascending = True)/df_all.shape[0]*100\n",
    "memtype.plot(kind='barh', title = 'Memtype')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['memtypeA'] = (df_all.memtype=='A')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['memtypeF'] = (df_all.memtype=='F')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all = df_all.drop('memtype', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mem_mag1 & mem_mag2 & hasemail\n",
    "\n",
    "- only yes or no... convert yes to 1, no to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFeCAYAAACsH5cdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAGAM8QYAwBjiDQCAMcQbAABj/g8VjRY/U6OGdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cbeb990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "memmag1 = df_all.groupby('mem_mag1').size().sort_values(ascending = True)/df_all.shape[0]*100\n",
    "memmag1.plot(kind='barh', title = 'mem_mag1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFeCAYAAAB+T51FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d015bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "memmag2 = df_all.groupby('mem_mag2').size().sort_values(ascending = True)/df_all.shape[0]*100\n",
    "memmag2.plot(kind='barh', title = 'mem_mag2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFeCAYAAACsH5cdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcQbAABjiDcAAMYQbwAAjCHeAAAY828pa7jssE1jJgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cbe2e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hasemail = df_all.groupby('hasemail').size().sort_values(ascending = True)/df_all.shape[0]*100\n",
    "hasemail.plot(kind='barh', title = 'hasemail')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.mem_mag1 = (df_all.mem_mag1.values=='Y')*1\n",
    "df_all.mem_mag2 = (df_all.mem_mag2.values=='Y')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.hasemail = (df_all.hasemail.values=='Y')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>age.na</th>\n",
       "      <th>r1.na</th>\n",
       "      <th>r2.na</th>\n",
       "      <th>r3.na</th>\n",
       "      <th>r.quick.na</th>\n",
       "      <th>r.intl.na</th>\n",
       "      <th>mon_less30</th>\n",
       "      <th>mon_31</th>\n",
       "      <th>mon_32</th>\n",
       "      <th>mon_33</th>\n",
       "      <th>mon_34</th>\n",
       "      <th>mon_35</th>\n",
       "      <th>mon_36</th>\n",
       "      <th>mon_37_60</th>\n",
       "      <th>mon_61_84</th>\n",
       "      <th>mon_85_120</th>\n",
       "      <th>mon_121_263</th>\n",
       "      <th>mon_264_plus</th>\n",
       "      <th>games_0</th>\n",
       "      <th>games_1_5</th>\n",
       "      <th>games_6_10</th>\n",
       "      <th>games_11_20</th>\n",
       "      <th>games_21_34</th>\n",
       "      <th>games_35_49</th>\n",
       "      <th>games_50_plus</th>\n",
       "      <th>agesq</th>\n",
       "      <th>agecbd</th>\n",
       "      <th>allgames1yrsq</th>\n",
       "      <th>allgames1yrcbd</th>\n",
       "      <th>allgames5yrsq</th>\n",
       "      <th>allgames5yrcbd</th>\n",
       "      <th>memmonthssq</th>\n",
       "      <th>memmonthscbd</th>\n",
       "      <th>memtypeA</th>\n",
       "      <th>memtypeF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>1557.56</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.99</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2178.00</td>\n",
       "      <td>2215.00</td>\n",
       "      <td>2291.00</td>\n",
       "      <td>2932.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.25</td>\n",
       "      <td>12.38</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.59</td>\n",
       "      <td>15.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>627.00</td>\n",
       "      <td>628.00</td>\n",
       "      <td>1362.00</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.53</td>\n",
       "      <td>15.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2600.00</td>\n",
       "      <td>2601.00</td>\n",
       "      <td>2602.00</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.74</td>\n",
       "      <td>11.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.19</td>\n",
       "      <td>16.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>464.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>958.00</td>\n",
       "      <td>1356.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.25</td>\n",
       "      <td>13.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  region  nregions  memmonths  mem_mag1  mem_mag2  hasemail      r1      r2      r3  r.quick extra intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  age.na  r1.na  r2.na  r3.na  r.quick.na  r.intl.na mon_less30 mon_31 mon_32 mon_33 mon_34 mon_35 mon_36 mon_37_60 mon_61_84 mon_85_120 mon_121_263 mon_264_plus games_0 games_1_5 games_6_10 games_11_20 games_21_34 games_35_49 games_50_plus  agesq  agecbd  allgames1yrsq  allgames1yrcbd  allgames5yrsq  \\\n",
       "0 11.00    0    0.12         1         19         0         0         0 1942.12 1811.61 1557.56  2007.74     N    N 3477.56            0            0           0          0           0       0       0      1      1      1           1          1       True  False  False  False  False  False  False     False     False      False       False        False    True     False      False       False       False       False         False   4.97    7.45           0.00            0.00           0.00   \n",
       "1 61.00    0    0.12         1        198         1         0         1 2178.00 2215.00 2291.00  2932.00     Y    N 3477.56            4           29           1          0          10       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False      True      False       False       False       False          True   8.25   12.38           3.22            4.83           6.80   \n",
       "2 16.00    1    0.12         1        192         0         0         1  627.00  628.00 1362.00  2007.00     N    N 3477.56           29           29           0          4           1       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False      False       False        True       False          True   5.67    8.50           6.80           10.20           6.80   \n",
       "3 47.00    0    0.12         1        268         1         0         1 2600.00 2601.00 2602.00  2007.74     N    N 3477.56            0            0           0          0           0       0       0      0      0      0           1          1      False  False  False  False  False  False  False     False     False      False       False         True    True     False      False       False       False       False          True   7.74   11.61           0.00            0.00           0.00   \n",
       "4 11.00    1    0.12         1        101         0         0         0  464.00  466.00  958.00  1356.00     N    N 3477.56           12           35           0          8           0       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False       True       False        False   False     False      False        True       False       False          True   4.97    7.45           5.13            7.69           7.17   \n",
       "\n",
       "   allgames5yrcbd  memmonthssq  memmonthscbd  memtypeA  memtypeF  \n",
       "0            0.00         5.99          8.99         0         0  \n",
       "1           10.20        10.59         15.88         0         0  \n",
       "2           10.20        10.53         15.79         0         0  \n",
       "3            0.00        11.19         16.78         0         0  \n",
       "4           10.75         9.25         13.87         0         0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extra, intl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFeCAYAAAB+T51FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d9feed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extra = df_all.groupby('extra').size().sort_values(ascending = True)/df_all.shape[0]*100\n",
    "extra.plot(kind='barh', title = 'extra')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFeCAYAAACsH5cdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3gBQjHgDQDHiDQDFiDcAFPM/+ic1i4HfanwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e1149d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "intl = df_all.groupby('intl').size().sort_values(ascending = True)/df_all.shape[0]*100\n",
    "intl.plot(kind='barh', title = 'intl')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.extra = (df_all.extra.values=='Y')*1\n",
    "df_all.intl = (df_all.intl.values=='Y')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>age.na</th>\n",
       "      <th>r1.na</th>\n",
       "      <th>r2.na</th>\n",
       "      <th>r3.na</th>\n",
       "      <th>r.quick.na</th>\n",
       "      <th>r.intl.na</th>\n",
       "      <th>mon_less30</th>\n",
       "      <th>mon_31</th>\n",
       "      <th>mon_32</th>\n",
       "      <th>mon_33</th>\n",
       "      <th>mon_34</th>\n",
       "      <th>mon_35</th>\n",
       "      <th>mon_36</th>\n",
       "      <th>mon_37_60</th>\n",
       "      <th>mon_61_84</th>\n",
       "      <th>mon_85_120</th>\n",
       "      <th>mon_121_263</th>\n",
       "      <th>mon_264_plus</th>\n",
       "      <th>games_0</th>\n",
       "      <th>games_1_5</th>\n",
       "      <th>games_6_10</th>\n",
       "      <th>games_11_20</th>\n",
       "      <th>games_21_34</th>\n",
       "      <th>games_35_49</th>\n",
       "      <th>games_50_plus</th>\n",
       "      <th>agesq</th>\n",
       "      <th>agecbd</th>\n",
       "      <th>allgames1yrsq</th>\n",
       "      <th>allgames1yrcbd</th>\n",
       "      <th>allgames5yrsq</th>\n",
       "      <th>allgames5yrcbd</th>\n",
       "      <th>memmonthssq</th>\n",
       "      <th>memmonthscbd</th>\n",
       "      <th>memtypeA</th>\n",
       "      <th>memtypeF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1942.12</td>\n",
       "      <td>1811.61</td>\n",
       "      <td>1557.56</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.99</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2178.00</td>\n",
       "      <td>2215.00</td>\n",
       "      <td>2291.00</td>\n",
       "      <td>2932.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>8.25</td>\n",
       "      <td>12.38</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.59</td>\n",
       "      <td>15.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>627.00</td>\n",
       "      <td>628.00</td>\n",
       "      <td>1362.00</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.53</td>\n",
       "      <td>15.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2600.00</td>\n",
       "      <td>2601.00</td>\n",
       "      <td>2602.00</td>\n",
       "      <td>2007.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.74</td>\n",
       "      <td>11.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.19</td>\n",
       "      <td>16.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>464.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>958.00</td>\n",
       "      <td>1356.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3477.56</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.45</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.25</td>\n",
       "      <td>13.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  region  nregions  memmonths  mem_mag1  mem_mag2  hasemail      r1      r2      r3  r.quick  extra  intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  age.na  r1.na  r2.na  r3.na  r.quick.na  r.intl.na mon_less30 mon_31 mon_32 mon_33 mon_34 mon_35 mon_36 mon_37_60 mon_61_84 mon_85_120 mon_121_263 mon_264_plus games_0 games_1_5 games_6_10 games_11_20 games_21_34 games_35_49 games_50_plus  agesq  agecbd  allgames1yrsq  allgames1yrcbd  allgames5yrsq  \\\n",
       "0 11.00    0    0.12         1         19         0         0         0 1942.12 1811.61 1557.56  2007.74      0     0 3477.56            0            0           0          0           0       0       0      1      1      1           1          1       True  False  False  False  False  False  False     False     False      False       False        False    True     False      False       False       False       False         False   4.97    7.45           0.00            0.00           0.00   \n",
       "1 61.00    0    0.12         1        198         1         0         1 2178.00 2215.00 2291.00  2932.00      1     0 3477.56            4           29           1          0          10       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False      True      False       False       False       False          True   8.25   12.38           3.22            4.83           6.80   \n",
       "2 16.00    1    0.12         1        192         0         0         1  627.00  628.00 1362.00  2007.00      0     0 3477.56           29           29           0          4           1       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False      False       False        True       False          True   5.67    8.50           6.80           10.20           6.80   \n",
       "3 47.00    0    0.12         1        268         1         0         1 2600.00 2601.00 2602.00  2007.74      0     0 3477.56            0            0           0          0           0       0       0      0      0      0           1          1      False  False  False  False  False  False  False     False     False      False       False         True    True     False      False       False       False       False          True   7.74   11.61           0.00            0.00           0.00   \n",
       "4 11.00    1    0.12         1        101         0         0         0  464.00  466.00  958.00  1356.00      0     0 3477.56           12           35           0          8           0       0       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False       True       False        False   False     False      False        True       False       False          True   4.97    7.45           5.13            7.69           7.17   \n",
       "\n",
       "   allgames5yrcbd  memmonthssq  memmonthscbd  memtypeA  memtypeF  \n",
       "0            0.00         5.99          8.99         0         0  \n",
       "1           10.20        10.59         15.88         0         0  \n",
       "2           10.20        10.53         15.79         0         0  \n",
       "3            0.00        11.19         16.78         0         0  \n",
       "4           10.75         9.25         13.87         0         0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### % change in chess rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['r3r2'] = df_all.r3 / df_all.r2 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['r3r1'] = df_all.r3 / df_all.r1 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['allgames_change'] = df_all.allgames1yr/((df_all.allgames5yr - df_all.allgames1yr + 1)/4)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['fastevets_prop'] = df_all.fastevents / (df_all.fastevents + df_all.medevents + df_all.slowevents+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['medevents_prop'] = df_all.medevents / (df_all.fastevents + df_all.medevents + df_all.slowevents+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['slowevents_prop'] = df_all.slowevents / (df_all.fastevents + df_all.medevents + df_all.slowevents+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO region is discrete?? \n",
    "# last 8 are sq and cubed terms \n",
    "STANDARDIZE = ['age', 'region', 'nregions', 'memmonths', 'r1', 'r2', 'r3', 'r.quick', 'r.intl', \n",
    "               'allgames1yr', 'allgames5yr', 'fastevents', 'medevents', 'slowevents', 'nfloor', \n",
    "              'agesq', 'agecbd', 'allgames1yrsq', 'allgames1yrcbd', 'allgames5yrsq', 'allgames5yrcbd', 'memmonthssq', \n",
    "               'memmonthscbd', 'r3r2', 'r3r1', 'allgames_change', 'fastevets_prop', 'medevents_prop', 'slowevents_prop']\n",
    "\n",
    "\n",
    "INDICATORS = ['sex', 'mem_mag1', 'mem_mag2', 'hasemail', 'extra', 'intl', 'age.na', 'r1.na', 'r2.na', \n",
    "             'r3.na', 'r.quick.na', 'r.intl.na', 'mon_less30', 'mon_31', 'mon_32', 'mon_33', 'mon_34', \n",
    "             'mon_35', 'mon_36', 'mon_37_60', 'mon_61_84', 'mon_85_120', 'mon_121_263', 'mon_264_plus', \n",
    "             'games_0', 'games_1_5', 'games_6_10', 'games_11_20', 'games_21_34', 'games_35_49', 'games_50_plus', \n",
    "             'memtypeA', 'memtypeF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(STANDARDIZE) + len(INDICATORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(df_all[STANDARDIZE])\n",
    "std = std_scale.transform(df_all[STANDARDIZE])\n",
    "df_all[STANDARDIZE] = std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>region</th>\n",
       "      <th>nregions</th>\n",
       "      <th>memmonths</th>\n",
       "      <th>mem_mag1</th>\n",
       "      <th>mem_mag2</th>\n",
       "      <th>hasemail</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>r3</th>\n",
       "      <th>r.quick</th>\n",
       "      <th>extra</th>\n",
       "      <th>intl</th>\n",
       "      <th>r.intl</th>\n",
       "      <th>allgames1yr</th>\n",
       "      <th>allgames5yr</th>\n",
       "      <th>fastevents</th>\n",
       "      <th>medevents</th>\n",
       "      <th>slowevents</th>\n",
       "      <th>nfloor</th>\n",
       "      <th>age.na</th>\n",
       "      <th>r1.na</th>\n",
       "      <th>r2.na</th>\n",
       "      <th>r3.na</th>\n",
       "      <th>r.quick.na</th>\n",
       "      <th>r.intl.na</th>\n",
       "      <th>mon_less30</th>\n",
       "      <th>mon_31</th>\n",
       "      <th>mon_32</th>\n",
       "      <th>mon_33</th>\n",
       "      <th>mon_34</th>\n",
       "      <th>mon_35</th>\n",
       "      <th>mon_36</th>\n",
       "      <th>mon_37_60</th>\n",
       "      <th>mon_61_84</th>\n",
       "      <th>mon_85_120</th>\n",
       "      <th>mon_121_263</th>\n",
       "      <th>mon_264_plus</th>\n",
       "      <th>games_0</th>\n",
       "      <th>games_1_5</th>\n",
       "      <th>games_6_10</th>\n",
       "      <th>games_11_20</th>\n",
       "      <th>games_21_34</th>\n",
       "      <th>games_35_49</th>\n",
       "      <th>games_50_plus</th>\n",
       "      <th>agesq</th>\n",
       "      <th>agecbd</th>\n",
       "      <th>allgames1yrsq</th>\n",
       "      <th>allgames1yrcbd</th>\n",
       "      <th>allgames5yrsq</th>\n",
       "      <th>allgames5yrcbd</th>\n",
       "      <th>memmonthssq</th>\n",
       "      <th>memmonthscbd</th>\n",
       "      <th>memtypeA</th>\n",
       "      <th>memtypeF</th>\n",
       "      <th>r3r2</th>\n",
       "      <th>r3r1</th>\n",
       "      <th>allgames_change</th>\n",
       "      <th>fastevets_prop</th>\n",
       "      <th>medevents_prop</th>\n",
       "      <th>slowevents_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1.58</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-1.57</td>\n",
       "      <td>-1.57</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>-0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.91</td>\n",
       "      <td>0</td>\n",
       "      <td>1.58</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.74</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1.58</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.91</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.20</td>\n",
       "      <td>0</td>\n",
       "      <td>1.58</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.12</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.37</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-1.57</td>\n",
       "      <td>-1.57</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>-0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1.58</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.24</td>\n",
       "      <td>-1.79</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.26</td>\n",
       "      <td>1.93</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  region  nregions  memmonths  mem_mag1  mem_mag2  hasemail    r1    r2    r3  r.quick  extra  intl  r.intl  allgames1yr  allgames5yr  fastevents  medevents  slowevents  nfloor  age.na  r1.na  r2.na  r3.na  r.quick.na  r.intl.na mon_less30 mon_31 mon_32 mon_33 mon_34 mon_35 mon_36 mon_37_60 mon_61_84 mon_85_120 mon_121_263 mon_264_plus games_0 games_1_5 games_6_10 games_11_20 games_21_34 games_35_49 games_50_plus  agesq  agecbd  allgames1yrsq  allgames1yrcbd  allgames5yrsq  \\\n",
       "0 -0.62    0    1.58     -0.18      -0.71         0         0         0 -0.01 -0.00 -0.00    -0.00      0     0   -0.00        -0.62        -0.52       -0.16      -0.46       -0.34   -0.07       0      1      1      1           1          1       True  False  False  False  False  False  False     False     False      False       False        False    True     False      False       False       False       False         False  -0.63   -0.63          -1.36           -1.36          -1.57   \n",
       "1  1.91    0    1.58     -0.18       0.52         1         0         1  0.35  0.53  0.79     0.79      1     0   -0.00        -0.45        -0.19        0.00      -0.46        0.50   -0.07       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False      True      False       False       False       False          True   1.74    1.74          -0.19           -0.19           0.45   \n",
       "2 -0.37    1    1.58     -0.18       0.48         0         0         1 -2.00 -1.58 -0.21    -0.00      0     0   -0.00         0.65        -0.19       -0.16      -0.22       -0.26   -0.07       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False      False        True        False   False     False      False       False        True       False          True  -0.13   -0.13           1.11            1.11           0.45   \n",
       "3  1.20    0    1.58     -0.18       1.00         1         0         1  0.99  1.05  1.12    -0.00      0     0   -0.00        -0.62        -0.52       -0.16      -0.46       -0.34   -0.07       0      0      0      0           1          1      False  False  False  False  False  False  False     False     False      False       False         True    True     False      False       False       False       False          True   1.37    1.37          -1.36           -1.36          -1.57   \n",
       "4 -0.62    1    1.58     -0.18      -0.15         0         0         0 -2.24 -1.79 -0.65    -0.56      0     0   -0.00        -0.10        -0.13       -0.16       0.03       -0.34   -0.07       0      0      0      0           0          1      False  False  False  False  False  False  False     False     False       True       False        False   False     False      False        True       False       False          True  -0.63   -0.63           0.50            0.50           0.56   \n",
       "\n",
       "   allgames5yrcbd  memmonthssq  memmonthscbd  memtypeA  memtypeF  r3r2  r3r1  allgames_change  fastevets_prop  medevents_prop  slowevents_prop  \n",
       "0           -1.57        -0.78         -0.78         0         0 -0.11 -0.11            -0.45           -0.29           -1.39            -0.61  \n",
       "1            0.45         0.92          0.92         0         0  0.24  0.29            -0.43            0.34           -1.39             2.21  \n",
       "2            0.45         0.90          0.90         0         0  2.48  2.10             2.91           -0.29            0.48             0.01  \n",
       "3           -1.57         1.14          1.14         0         0  0.17  0.21            -0.45           -0.29           -1.39            -0.61  \n",
       "4            0.56         0.43          0.43         0         0  2.26  1.93            -0.39           -0.29            0.94            -0.61  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Females\n",
    "importance_list = clfForest.feature_importances_\n",
    "name_list = all_features\n",
    "importance_list, name_list = zip(*sorted(zip(importance_list, name_list)))\n",
    "# just get top (in reverse order)\n",
    "top_imp = importance_list[-20:]\n",
    "top_names = name_list[-20:]\n",
    "plt.barh(range(len(top_names)),top_imp,align='center')\n",
    "plt.yticks(range(len(top_names)),top_names)\n",
    "plt.xlabel('Relative Importance in the Random Forest')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Relative importance of Top 20 Features for Females')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "track_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "df_all\n",
    "test_idx\n",
    "train_y\n",
    "test_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.53331\n",
      "Test set error = 0.53896\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51658\n",
      "Test set error = 0.54433\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47279\n",
      "Test set error = 0.54265\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.53306\n",
      "Test set error = 0.53874\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51681\n",
      "Test set error = 0.54296\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47703\n",
      "Test set error = 0.53596\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.53181\n",
      "Test set error = 0.54398\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51751\n",
      "Test set error = 0.53963\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47839\n",
      "Test set error = 0.53838\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.53103\n",
      "Test set error = 0.54598\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51951\n",
      "Test set error = 0.52904\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47437\n",
      "Test set error = 0.53955\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.53212\n",
      "Test set error = 0.54339\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51688\n",
      "Test set error = 0.53943\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47889\n",
      "Test set error = 0.53788\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.53249\n",
      "Test set error = 0.53645\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51774\n",
      "Test set error = 0.53623\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.48105\n",
      "Test set error = 0.53307\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.53144\n",
      "Test set error = 0.54517\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51676\n",
      "Test set error = 0.54010\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47829\n",
      "Test set error = 0.52712\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.53311\n",
      "Test set error = 0.53775\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51826\n",
      "Test set error = 0.53192\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47602\n",
      "Test set error = 0.53883\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.53138\n",
      "Test set error = 0.54208\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51425\n",
      "Test set error = 0.54890\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47843\n",
      "Test set error = 0.53757\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52526\n",
      "Test set error = 0.53465\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50172\n",
      "Test set error = 0.53356\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.43261\n",
      "Test set error = 0.53891\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52376\n",
      "Test set error = 0.53897\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50327\n",
      "Test set error = 0.53104\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.44203\n",
      "Test set error = 0.53790\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52574\n",
      "Test set error = 0.53136\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50325\n",
      "Test set error = 0.53851\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.44096\n",
      "Test set error = 0.54427\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52546\n",
      "Test set error = 0.53305\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50198\n",
      "Test set error = 0.53123\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.43547\n",
      "Test set error = 0.54319\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52313\n",
      "Test set error = 0.53887\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50317\n",
      "Test set error = 0.52866\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.43651\n",
      "Test set error = 0.54523\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52609\n",
      "Test set error = 0.52782\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50072\n",
      "Test set error = 0.53910\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.75, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.44754\n",
      "Test set error = 0.53619\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52357\n",
      "Test set error = 0.53751\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49914\n",
      "Test set error = 0.54145\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.43263\n",
      "Test set error = 0.55444\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52470\n",
      "Test set error = 0.53248\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.49907\n",
      "Test set error = 0.54498\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.43836\n",
      "Test set error = 0.54203\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.52363\n",
      "Test set error = 0.53716\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.50129\n",
      "Test set error = 0.53768\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
      "              min_samples_leaf=45, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.44300\n",
      "Test set error = 0.53764\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=2, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.51136\n",
      "Test set error = 0.53653\n",
      "----------\n",
      "############\n",
      "############\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=0.6, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------\n",
      "Training set error = 0.47544\n",
      "Test set error = 0.54793\n",
      "----------\n",
      "############\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-43aebec09b0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                 p2.get_pred_np(modelboost, df_all, train_y, 'RFBoost', track_dict=None, \n\u001b[1;32m     16\u001b[0m                             \u001b[0mtest_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                             score_func='log_loss', predict=False)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amylee/Documents/Classes/Spring-2016/Stat149/stat149project/Amy/amyutility.pyc\u001b[0m in \u001b[0;36mget_pred_np\u001b[0;34m(model, dataframe, train_y, model_name, track_dict, test_idx, train_size, columns, parameters, score_func, n_folds, predict)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecond_half_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_half_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mresults_1st_half\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_half_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;31m# concatenate back together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_1st_half\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_2nd_half\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amylee/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1025\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1026\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amylee/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1078\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1079\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amylee/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 784\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amylee/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            max_leaf_nodes)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "estimators = [250, 500, 1000] # default = 10\n",
    "features = [0.6, 0.75, 0.9] # default = 'sqrt'\n",
    "samples = [25, 35, 45] # default = 1\n",
    "max_depth = [2, 3, 5]\n",
    "\n",
    "for e in estimators:\n",
    "    for f in features: \n",
    "        for s in samples: \n",
    "            for d in max_depth: \n",
    "                modelboost = GradientBoostingClassifier(n_estimators=e, max_features=f, min_samples_leaf=s, \n",
    "                                                   max_depth=d)\n",
    "                p2.get_pred_np(modelboost, df_all, train_y, 'RFBoost', track_dict=None, \n",
    "                            test_idx=test_idx, train_size=0.8, columns=None, parameters=None, \n",
    "                            score_func='log_loss', predict=False)\n",
    "\n",
    "\n",
    "# option to save fitted model\n",
    "# joblib.dump(model, 'models/baseline_logistic.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
    "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
    "              min_samples_leaf=25, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
    "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "----------\n",
    "Training set error = 0.51951\n",
    "Test set error = 0.52904\n",
    "\n",
    "\n",
    "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
    "              max_depth=5, max_features=0.9, max_leaf_nodes=None,\n",
    "              min_samples_leaf=25, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
    "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "----------\n",
    "Training set error = 0.47829\n",
    "Test set error = 0.52712\n",
    "\n",
    "\n",
    "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
    "              max_depth=2, max_features=0.75, max_leaf_nodes=None,\n",
    "              min_samples_leaf=45, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "----------\n",
    "Training set error = 0.52609\n",
    "Test set error = 0.52782\n",
    "\n",
    "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
    "              max_depth=3, max_features=0.75, max_leaf_nodes=None,\n",
    "              min_samples_leaf=35, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "----------\n",
    "Training set error = 0.50317\n",
    "Test set error = 0.52866"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43436,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HERE NOW\n",
    "def half_half(model, dataframe, train_y, test_idx=None, cut_idx=20000):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    vals = dataframe.values\n",
    "\n",
    "    # Separate prediction data out\n",
    "    x_train_full = vals[:test_idx]\n",
    "\n",
    "    # Separate into half and half\n",
    "    first_half_x = x_train_full[:cut_idx]\n",
    "    second_half_x = x_train_full[cut_idx:]\n",
    "    \n",
    "    first_half_y = train_y[:cut_idx]\n",
    "    second_half_y = train_y[cut_idx:]\n",
    "    \n",
    "    # train first half, predict on second half\n",
    "    model.fit(first_half_x, first_half_y)\n",
    "    results_2nd_half = model.predict_proba(second_half_x)\n",
    "    \n",
    "    # train on 2nd half, predict on first half \n",
    "    model.fit(second_half_x, second_half_y)\n",
    "    results_1st_half = model.predict_proba(first_half_x)\n",
    "    \n",
    "    # concatenate back together \n",
    "    results = np.vstack((results_1st_half, results_2nd_half))\n",
    "    \n",
    "    return results[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelboost = GradientBoostingClassifier(n_estimators=500, max_features=0.75, min_samples_leaf=35, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbx_train_predict = half_half(modelboost, df_all, train_y, test_idx=test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43436,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbx_train_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54163715711254656"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(train_y, gbx_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({'lapsed': gbx_train_predict})\n",
    "\n",
    "# write to csv, with header, drop index\n",
    "predictions.to_csv('predictions/train_predictions/gradient_boost_half_train.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('predictions/train_predictions/gradient_boost_half_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.93513174,  0.1878141 ,  0.76873221, ...,  0.57223588,\n",
       "        0.46663117,  0.72222439])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.lapsed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54163715711255211"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(train_y, test.lapsed.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ENTIRE DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predrf = p2.fit_and_predict(modelboost, df_all, train_y, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file('predictions/RF_Ken_asis2.csv', predrf[:, 1], test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_loss(train_y, modelrf.predict_proba(df_all[:test_idx])[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "----------\n",
      "Training set error = 0.55833\n",
      "Test set error = 0.56850\n",
      "----------\n",
      "############\n",
      "666.8 seconds runtime\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "modelsvc = SVC(probability=True, C=0.5)\n",
    "# probability=True, C=0.5\n",
    "\n",
    "Cs=[0.001, 0.01, 0.1, 1] # default = 1, try 0.01, 0.1, 1, 10, 100\n",
    "# penalties = ['l1', 'l2'] \n",
    "params = {'C': Cs, 'probability': [True]} # 'penalty': penalties\n",
    "\n",
    "predlr = p2.get_pred(modelsvc, df_all, train_y, 'SVM', test_idx=test_idx, train_size=0.8, \n",
    "                     columns=None, parameters=None, score_func='log_loss', n_folds=5, predict=False)\n",
    "\n",
    "print '%0.1f seconds runtime' % (time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kaggle 0.56438\n",
    "\n",
    "############\n",
    "SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
    "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "----------\n",
    "Training set error = 0.55833\n",
    "Test set error = 0.56850\n",
    "----------\n",
    "############\n",
    "666.8 seconds runtime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############\n",
    "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
    "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "----------\n",
    "Training set error = 0.55306\n",
    "Test set error = 0.56882\n",
    "----------\n",
    "############\n",
    "656.4 seconds runtime\n",
    "\n",
    "############\n",
    "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
    "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "----------\n",
    "Training set error = 0.56469\n",
    "Test set error = 0.56955\n",
    "----------\n",
    "############\n",
    "673.8 seconds runtime\n",
    "\n",
    "############\n",
    "SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
    "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "----------\n",
    "Training set error = 0.57718\n",
    "Test set error = 0.57873\n",
    "----------\n",
    "############\n",
    "727.7 seconds runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelsvm = SVC(probability=True, C=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predsvm = p2.fit_and_predict(modelsvm, df_all, train_y, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14479,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsvm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14479,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77880354,  0.64681566,  0.77953396, ...,  0.55816636,\n",
       "        0.78471993,  0.57812024])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55911502200987395"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle 0.56438\n",
    "log_loss(train_y, modelsvm.predict_proba(df_all[:test_idx])[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p2.write_to_file('predictions/SVM.csv', predsvm, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_train_predict = half_half(modelsvm, df_all, train_y, test_idx=test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43436,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_train_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56668835199575518"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(train_y, svm_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({'lapsed': svm_train_predict})\n",
    "\n",
    "# write to csv, with header, drop index\n",
    "predictions.to_csv('predictions/train_predictions/svm_half_train.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=50, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=100, p=2,\n",
      "           weights='uniform')\n",
      "----------\n",
      "Training set error = 0.55126\n",
      "Test set error = 0.55840\n",
      "----------\n",
      "############\n",
      "############\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=50, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=200, p=2,\n",
      "           weights='uniform')\n",
      "----------\n",
      "Training set error = 0.55838\n",
      "Test set error = 0.56255\n",
      "----------\n",
      "############\n",
      "############\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=50, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=300, p=2,\n",
      "           weights='uniform')\n",
      "----------\n",
      "Training set error = 0.56230\n",
      "Test set error = 0.56644\n",
      "----------\n",
      "############\n"
     ]
    }
   ],
   "source": [
    "# TODO HERE NOW \n",
    "\n",
    "# parameters\n",
    "n_neighbors = [100, 200, 300] # default = 5\n",
    "weights = ['uniform']\n",
    "leaf_size = [50]\n",
    "\n",
    "for n in n_neighbors:\n",
    "    for w in weights: \n",
    "        for l in leaf_size: \n",
    "            knn = KNeighborsClassifier(n_neighbors=n, weights=w, leaf_size=l, n_jobs=-1)\n",
    "            p2.get_pred(knn, df_all, train_y, 'KNN', track_dict=None, test_idx=test_idx, train_size=0.8, \n",
    "                     columns=None, parameters=None, score_func='log_loss', predict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO \n",
    "\n",
    "############\n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=20, metric='minkowski',\n",
    "           metric_params=None, n_jobs=-1, n_neighbors=50, p=2,\n",
    "           weights='uniform')\n",
    "----------\n",
    "Training set error = 0.54334\n",
    "Test set error = 0.55617\n",
    "----------\n",
    "\n",
    "############\n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=20, metric='minkowski',\n",
    "           metric_params=None, n_jobs=-1, n_neighbors=200, p=2,\n",
    "           weights='uniform')\n",
    "----------\n",
    "Training set error = 0.55898\n",
    "Test set error = 0.55945\n",
    "----------\n",
    "############\n",
    "############\n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=-1, n_neighbors=300, p=2,\n",
    "           weights='uniform')\n",
    "----------\n",
    "Training set error = 0.56436\n",
    "Test set error = 0.55949\n",
    "----------\n",
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelknn = KNeighborsClassifier(n_neighbors=50, leaf_size=20, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predknn = p2.fit_and_predict(modelknn, df_all, train_y, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14479,)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predknn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54034247089710319"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(train_y, modelknn.predict_proba(df_all[:test_idx])[:, 1])\n",
    "\n",
    "# Kaggle 0.55957\n",
    "# validation 0.55617"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p2.write_to_file('predictions/KNN.csv', predknn, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_train_predict = half_half(modelknn, df_all, train_y, test_idx=test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43436,)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_train_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56731825886556775"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(train_y, knn_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({'lapsed': knn_train_predict})\n",
    "\n",
    "# write to csv, with header, drop index\n",
    "predictions.to_csv('predictions/train_predictions/knn_half_train.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
